{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import gym\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from stable_baselines.common.cmd_util import mujoco_arg_parser\n",
    "from stable_baselines import bench, logger\n",
    "from stable_baselines.common import set_global_seeds\n",
    "from stable_baselines.common.vec_env.vec_normalize import VecNormalize\n",
    "from stable_baselines.ppo1 import PPO1\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, CnnPolicy\n",
    "from stable_baselines.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "home = str(Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from mpi4py import MPI\n",
    "\n",
    "from stable_baselines.common import Dataset, explained_variance, fmt_row, zipsame, ActorCriticRLModel, SetVerbosity, \\\n",
    "    TensorboardWriter\n",
    "import stable_baselines.common.tf_util as tf_util\n",
    "from stable_baselines.common.policies import LstmPolicy, ActorCriticPolicy\n",
    "from stable_baselines.common.mpi_adam import MpiAdam\n",
    "from stable_baselines.common.mpi_moments import mpi_moments\n",
    "from stable_baselines.trpo_mpi.utils import add_vtarg_and_adv, flatten_lists\n",
    "from stable_baselines.a2c.utils import total_episode_reward_logger\n",
    "\n",
    "from stable_baselines.common.vec_env import VecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj_segment_generator(policy, env, horizon, reward_giver=None, gail=False):\n",
    "    \"\"\"\n",
    "    Compute target value using TD(lambda) estimator, and advantage with GAE(lambda)\n",
    "    :param policy: (MLPPolicy) the policy\n",
    "    :param env: (Gym Environment) the environment\n",
    "    :param horizon: (int) the number of timesteps to run per batch\n",
    "    :param reward_giver: (TransitionClassifier) the reward predicter from obsevation and action\n",
    "    :param gail: (bool) Whether we are using this generator for standard trpo or with gail\n",
    "    :return: (dict) generator that returns a dict with the following keys:\n",
    "        - ob: (np.ndarray) observations\n",
    "        - rew: (numpy float) rewards (if gail is used it is the predicted reward)\n",
    "        - vpred: (numpy float) action logits\n",
    "        - new: (numpy bool) dones (is end of episode)\n",
    "        - ac: (np.ndarray) actions\n",
    "        - prevac: (np.ndarray) previous actions\n",
    "        - nextvpred: (numpy float) next action logits\n",
    "        - ep_rets: (float) cumulated current episode reward\n",
    "        - ep_lens: (int) the length of the current episode\n",
    "        - ep_true_rets: (float) the real environment reward\n",
    "    \"\"\"\n",
    "    # Check when using GAIL\n",
    "    assert not (gail and reward_giver is None), \"You must pass a reward giver when using GAIL\"\n",
    "\n",
    "    # Initialize state variables\n",
    "    step = 0\n",
    "    action = env.action_space.sample()  # not used, just so we have the datatype\n",
    "    new = True\n",
    "    observation = env.reset()\n",
    "\n",
    "    cur_ep_ret = 0  # return in current episode\n",
    "    cur_ep_len = 0  # len of current episode\n",
    "    cur_ep_true_ret = 0\n",
    "    ep_true_rets = []\n",
    "    ep_rets = []  # returns of completed episodes in this segment\n",
    "    ep_lens = []  # Episode lengths\n",
    "\n",
    "    # Initialize history arrays\n",
    "    observations = np.array([observation for _ in range(horizon)])\n",
    "    true_rews = np.zeros(horizon, 'float32')\n",
    "    rews = np.zeros(horizon, 'float32')\n",
    "    vpreds = np.zeros(horizon, 'float32')\n",
    "    dones = np.zeros(horizon, 'int32')\n",
    "    actions = np.array([action for _ in range(horizon)])\n",
    "    prev_actions = actions.copy()\n",
    "    states = policy.initial_state\n",
    "    done = None\n",
    "\n",
    "    action_history = []\n",
    "    prevac = action\n",
    "    while True:\n",
    "        action_history.append(action)\n",
    "        prevprevac = prevac\n",
    "        prevac = action\n",
    "        action, vpred, states, _ = policy.step(observation.reshape(-1, *observation.shape), states, done)\n",
    "        # Slight weirdness here because we need value function at time T\n",
    "        # before returning segment [0, T-1] so we get the correct\n",
    "        # terminal value\n",
    "        if step > 0 and step % horizon == 0:\n",
    "            # Fix to avoid \"mean of empty slice\" warning when there is only one episode\n",
    "            if len(ep_rets) == 0:\n",
    "                ep_rets = [cur_ep_ret]\n",
    "                ep_lens = [cur_ep_len]\n",
    "                ep_true_rets = [cur_ep_true_ret]\n",
    "                total_timesteps = cur_ep_len\n",
    "            else:\n",
    "                total_timesteps = sum(ep_lens) + cur_ep_len\n",
    "\n",
    "            yield {\"ob\": observations, \"rew\": rews, \"dones\": dones, \"true_rew\": true_rews, \"vpred\": vpreds,\n",
    "                   \"ac\": actions, \"prevac\": prev_actions, \"nextvpred\": vpred * (1 - new), \"ep_rets\": ep_rets,\n",
    "                   \"ep_lens\": ep_lens, \"ep_true_rets\": ep_true_rets, \"total_timestep\": total_timesteps}\n",
    "            _, vpred, _, _ = policy.step(observation.reshape(-1, *observation.shape))\n",
    "            # Be careful!!! if you change the downstream algorithm to aggregate\n",
    "            # several of these batches, then be sure to do a deepcopy\n",
    "            ep_rets = []\n",
    "            ep_true_rets = []\n",
    "            ep_lens = []\n",
    "        i = step % horizon\n",
    "        observations[i] = observation\n",
    "        vpreds[i] = vpred[0]\n",
    "        actions[i] = action[0]\n",
    "        prev_actions[i] = prevac\n",
    "\n",
    "        clipped_action = action\n",
    "        # Clip the actions to avoid out of bound error\n",
    "        if isinstance(env.action_space, gym.spaces.Box):\n",
    "            clipped_action = np.clip(action, env.action_space.low, env.action_space.high)\n",
    "\n",
    "        if gail:\n",
    "            rew = reward_giver.get_reward(observation, clipped_action[0])\n",
    "            observation, true_rew, done, _info = env.step(clipped_action[0])\n",
    "        else:\n",
    "            observation, rew, done, _info = env.step(clipped_action[0])\n",
    "            true_rew = rew\n",
    "            \n",
    "        \"\"\"*************\"\"\"\n",
    "        if prevprevac == 2 and prevac == 2 and action == 3:\n",
    "            rew += 0.25\n",
    "        if prevprevac == 3 and prevac == 3 and action == 2:\n",
    "            rew += 0.25\n",
    "        \n",
    "        \"\"\"*************\"\"\"\n",
    "        \n",
    "        rews[i] = rew\n",
    "        true_rews[i] = true_rew\n",
    "        dones[i] = done\n",
    "\n",
    "        cur_ep_ret += rew\n",
    "        cur_ep_true_ret += true_rew\n",
    "        cur_ep_len += 1\n",
    "        if done:\n",
    "            ep_rets.append(cur_ep_ret)\n",
    "            ep_true_rets.append(cur_ep_true_ret)\n",
    "            ep_lens.append(cur_ep_len)\n",
    "            cur_ep_ret = 0\n",
    "            cur_ep_true_ret = 0\n",
    "            cur_ep_len = 0\n",
    "            if not isinstance(env, VecEnv):\n",
    "                observation = env.reset()\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO1_Mod(ActorCriticRLModel):\n",
    "    \"\"\"\n",
    "    Proximal Policy Optimization algorithm (MPI version).\n",
    "    Paper: https://arxiv.org/abs/1707.06347\n",
    "    :param env: (Gym environment or str) The environment to learn from (if registered in Gym, can be str)\n",
    "    :param policy: (ActorCriticPolicy or str) The policy model to use (MlpPolicy, CnnPolicy, CnnLstmPolicy, ...)\n",
    "    :param timesteps_per_actorbatch: (int) timesteps per actor per update\n",
    "    :param clip_param: (float) clipping parameter epsilon\n",
    "    :param entcoeff: (float) the entropy loss weight\n",
    "    :param optim_epochs: (float) the optimizer's number of epochs\n",
    "    :param optim_stepsize: (float) the optimizer's stepsize\n",
    "    :param optim_batchsize: (int) the optimizer's the batch size\n",
    "    :param gamma: (float) discount factor\n",
    "    :param lam: (float) advantage estimation\n",
    "    :param adam_epsilon: (float) the epsilon value for the adam optimizer\n",
    "    :param schedule: (str) The type of scheduler for the learning rate update ('linear', 'constant',\n",
    "        'double_linear_con', 'middle_drop' or 'double_middle_drop')\n",
    "    :param verbose: (int) the verbosity level: 0 none, 1 training information, 2 tensorflow debug\n",
    "    :param tensorboard_log: (str) the log location for tensorboard (if None, no logging)\n",
    "    :param _init_setup_model: (bool) Whether or not to build the network at the creation of the instance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, policy, env, gamma=0.99, timesteps_per_actorbatch=256, clip_param=0.2, entcoeff=0.01,\n",
    "                 optim_epochs=4, optim_stepsize=1e-3, optim_batchsize=64, lam=0.95, adam_epsilon=1e-5,\n",
    "                 schedule='linear', verbose=0, tensorboard_log=None, _init_setup_model=True):\n",
    "\n",
    "        super().__init__(policy=policy, env=env, verbose=verbose, requires_vec_env=False,\n",
    "                         _init_setup_model=_init_setup_model)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.timesteps_per_actorbatch = timesteps_per_actorbatch\n",
    "        self.clip_param = clip_param\n",
    "        self.entcoeff = entcoeff\n",
    "        self.optim_epochs = optim_epochs\n",
    "        self.optim_stepsize = optim_stepsize\n",
    "        self.optim_batchsize = optim_batchsize\n",
    "        self.lam = lam\n",
    "        self.adam_epsilon = adam_epsilon\n",
    "        self.schedule = schedule\n",
    "        self.tensorboard_log = tensorboard_log\n",
    "\n",
    "        self.graph = None\n",
    "        self.sess = None\n",
    "        self.policy_pi = None\n",
    "        self.loss_names = None\n",
    "        self.lossandgrad = None\n",
    "        self.adam = None\n",
    "        self.assign_old_eq_new = None\n",
    "        self.compute_losses = None\n",
    "        self.params = None\n",
    "        self.step = None\n",
    "        self.proba_step = None\n",
    "        self.initial_state = None\n",
    "        self.summary = None\n",
    "        self.episode_reward = None\n",
    "\n",
    "        if _init_setup_model:\n",
    "            self.setup_model()\n",
    "\n",
    "    def setup_model(self):\n",
    "        with SetVerbosity(self.verbose):\n",
    "\n",
    "            self.graph = tf.Graph()\n",
    "            with self.graph.as_default():\n",
    "                self.sess = tf_util.single_threaded_session(graph=self.graph)\n",
    "\n",
    "                # Construct network for new policy\n",
    "                self.policy_pi = self.policy(self.sess, self.observation_space, self.action_space, self.n_envs, 1,\n",
    "                                             None, reuse=False)\n",
    "\n",
    "                # Network for old policy\n",
    "                with tf.variable_scope(\"oldpi\", reuse=False):\n",
    "                    old_pi = self.policy(self.sess, self.observation_space, self.action_space, self.n_envs, 1,\n",
    "                                         None, reuse=False)\n",
    "\n",
    "                with tf.variable_scope(\"loss\", reuse=False):\n",
    "                    # Target advantage function (if applicable)\n",
    "                    atarg = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "                    # Empirical return\n",
    "                    ret = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "                    # learning rate multiplier, updated with schedule\n",
    "                    lrmult = tf.placeholder(name='lrmult', dtype=tf.float32, shape=[])\n",
    "\n",
    "                    # Annealed cliping parameter epislon\n",
    "                    clip_param = self.clip_param * lrmult\n",
    "\n",
    "                    obs_ph = self.policy_pi.obs_ph\n",
    "                    action_ph = self.policy_pi.pdtype.sample_placeholder([None])\n",
    "\n",
    "                    kloldnew = old_pi.proba_distribution.kl(self.policy_pi.proba_distribution)\n",
    "                    ent = self.policy_pi.proba_distribution.entropy()\n",
    "                    meankl = tf.reduce_mean(kloldnew)\n",
    "                    meanent = tf.reduce_mean(ent)\n",
    "                    pol_entpen = (-self.entcoeff) * meanent\n",
    "\n",
    "                    # pnew / pold\n",
    "                    ratio = tf.exp(self.policy_pi.proba_distribution.logp(action_ph) -\n",
    "                                   old_pi.proba_distribution.logp(action_ph))\n",
    "\n",
    "                    # surrogate from conservative policy iteration\n",
    "                    surr1 = ratio * atarg\n",
    "                    surr2 = tf.clip_by_value(ratio, 1.0 - clip_param, 1.0 + clip_param) * atarg\n",
    "\n",
    "                    # PPO's pessimistic surrogate (L^CLIP)\n",
    "                    pol_surr = - tf.reduce_mean(tf.minimum(surr1, surr2))\n",
    "                    vf_loss = tf.reduce_mean(tf.square(self.policy_pi.value_fn[:, 0] - ret))\n",
    "                    total_loss = pol_surr + pol_entpen + vf_loss\n",
    "                    losses = [pol_surr, pol_entpen, vf_loss, meankl, meanent]\n",
    "                    self.loss_names = [\"pol_surr\", \"pol_entpen\", \"vf_loss\", \"kl\", \"ent\"]\n",
    "\n",
    "                    tf.summary.scalar('entropy_loss', pol_entpen)\n",
    "                    tf.summary.scalar('policy_gradient_loss', pol_surr)\n",
    "                    tf.summary.scalar('value_function_loss', vf_loss)\n",
    "                    tf.summary.scalar('approximate_kullback-leiber', meankl)\n",
    "                    tf.summary.scalar('clip_factor', clip_param)\n",
    "                    tf.summary.scalar('loss', total_loss)\n",
    "\n",
    "                    self.params = tf_util.get_trainable_vars(\"model\")\n",
    "\n",
    "                    self.assign_old_eq_new = tf_util.function(\n",
    "                        [], [], updates=[tf.assign(oldv, newv) for (oldv, newv) in\n",
    "                                         zipsame(tf_util.get_globals_vars(\"oldpi\"), tf_util.get_globals_vars(\"model\"))])\n",
    "\n",
    "                with tf.variable_scope(\"Adam_mpi\", reuse=False):\n",
    "                    self.adam = MpiAdam(self.params, epsilon=self.adam_epsilon, sess=self.sess)\n",
    "\n",
    "                with tf.variable_scope(\"input_info\", reuse=False):\n",
    "                    tf.summary.scalar('discounted_rewards', tf.reduce_mean(ret))\n",
    "                    tf.summary.histogram('discounted_rewards', ret)\n",
    "                    tf.summary.scalar('learning_rate', tf.reduce_mean(self.optim_stepsize))\n",
    "                    tf.summary.histogram('learning_rate', self.optim_stepsize)\n",
    "                    tf.summary.scalar('advantage', tf.reduce_mean(atarg))\n",
    "                    tf.summary.histogram('advantage', atarg)\n",
    "                    tf.summary.scalar('clip_range', tf.reduce_mean(self.clip_param))\n",
    "                    tf.summary.histogram('clip_range', self.clip_param)\n",
    "                    #if len(self.observation_space.shape) == 3:\n",
    "                    #    tf.summary.image('observation', obs_ph)\n",
    "                    #else:\n",
    "                    #    tf.summary.histogram('observation', obs_ph)\n",
    "\n",
    "                self.step = self.policy_pi.step\n",
    "                self.proba_step = self.policy_pi.proba_step\n",
    "                self.initial_state = self.policy_pi.initial_state\n",
    "\n",
    "                tf_util.initialize(sess=self.sess)\n",
    "\n",
    "                self.summary = tf.summary.merge_all()\n",
    "\n",
    "                self.lossandgrad = tf_util.function([obs_ph, old_pi.obs_ph, action_ph, atarg, ret, lrmult],\n",
    "                                                    [self.summary, tf_util.flatgrad(total_loss, self.params)] + losses)\n",
    "                self.compute_losses = tf_util.function([obs_ph, old_pi.obs_ph, action_ph, atarg, ret, lrmult],\n",
    "                                                       losses)\n",
    "\n",
    "    def learn(self, total_timesteps, callback=None, seed=None, log_interval=100, tb_log_name=\"PPO1\"):\n",
    "        with SetVerbosity(self.verbose), TensorboardWriter(self.graph, self.tensorboard_log, tb_log_name) as writer:\n",
    "            self._setup_learn(seed)\n",
    "\n",
    "            assert issubclass(self.policy, ActorCriticPolicy), \"Error: the input policy for the PPO1 model must be \" \\\n",
    "                                                               \"an instance of common.policies.ActorCriticPolicy.\"\n",
    "\n",
    "            with self.sess.as_default():\n",
    "                self.adam.sync()\n",
    "\n",
    "                # Prepare for rollouts\n",
    "                seg_gen = traj_segment_generator(self.policy_pi, self.env, self.timesteps_per_actorbatch)\n",
    "\n",
    "                episodes_so_far = 0\n",
    "                timesteps_so_far = 0\n",
    "                iters_so_far = 0\n",
    "                t_start = time.time()\n",
    "\n",
    "                # rolling buffer for episode lengths\n",
    "                lenbuffer = deque(maxlen=100)\n",
    "                # rolling buffer for episode rewards\n",
    "                rewbuffer = deque(maxlen=100)\n",
    "\n",
    "                self.episode_reward = np.zeros((self.n_envs,))\n",
    "\n",
    "                while True:\n",
    "                    if callback is not None:\n",
    "                        # Only stop training if return value is False, not when it is None. This is for backwards\n",
    "                        # compatibility with callbacks that have no return statement.\n",
    "                        if callback(locals(), globals()) == False:\n",
    "                            break\n",
    "\n",
    "                    if total_timesteps and timesteps_so_far >= total_timesteps:\n",
    "                        break\n",
    "\n",
    "                    if self.schedule == 'constant':\n",
    "                        cur_lrmult = 1.0\n",
    "                    elif self.schedule == 'linear':\n",
    "                        cur_lrmult = max(1.0 - float(timesteps_so_far) / total_timesteps, 0)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "\n",
    "                    logger.log(\"********** Iteration %i ************\" % iters_so_far)\n",
    "\n",
    "                    seg = seg_gen.__next__()\n",
    "                    add_vtarg_and_adv(seg, self.gamma, self.lam)\n",
    "\n",
    "                    # ob, ac, atarg, ret, td1ret = map(np.concatenate, (obs, acs, atargs, rets, td1rets))\n",
    "                    obs_ph, action_ph, atarg, tdlamret = seg[\"ob\"], seg[\"ac\"], seg[\"adv\"], seg[\"tdlamret\"]\n",
    "\n",
    "                    # true_rew is the reward without discount\n",
    "                    if writer is not None:\n",
    "                        self.episode_reward = total_episode_reward_logger(self.episode_reward,\n",
    "                                                                          seg[\"true_rew\"].reshape((self.n_envs, -1)),\n",
    "                                                                          seg[\"dones\"].reshape((self.n_envs, -1)),\n",
    "                                                                          writer, timesteps_so_far)\n",
    "\n",
    "                    # predicted value function before udpate\n",
    "                    vpredbefore = seg[\"vpred\"]\n",
    "\n",
    "                    # standardized advantage function estimate\n",
    "                    atarg = (atarg - atarg.mean()) / atarg.std()\n",
    "                    dataset = Dataset(dict(ob=obs_ph, ac=action_ph, atarg=atarg, vtarg=tdlamret),\n",
    "                                      shuffle=not issubclass(self.policy, LstmPolicy))\n",
    "                    optim_batchsize = self.optim_batchsize or obs_ph.shape[0]\n",
    "\n",
    "                    # set old parameter values to new parameter values\n",
    "                    self.assign_old_eq_new(sess=self.sess)\n",
    "                    logger.log(\"Optimizing...\")\n",
    "                    logger.log(fmt_row(13, self.loss_names))\n",
    "\n",
    "                    # Here we do a bunch of optimization epochs over the data\n",
    "                    for k in range(self.optim_epochs):\n",
    "                        # list of tuples, each of which gives the loss for a minibatch\n",
    "                        losses = []\n",
    "                        for i, batch in enumerate(dataset.iterate_once(optim_batchsize)):\n",
    "                            steps = (timesteps_so_far +\n",
    "                                     k * optim_batchsize +\n",
    "                                     int(i * (optim_batchsize / len(dataset.data_map))))\n",
    "                            if writer is not None:\n",
    "                                # run loss backprop with summary, but once every 10 runs save the metadata\n",
    "                                # (memory, compute time, ...)\n",
    "                                if (1 + k) % 10 == 0:\n",
    "                                    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                                    run_metadata = tf.RunMetadata()\n",
    "                                    summary, grad, *newlosses = self.lossandgrad(batch[\"ob\"], batch[\"ob\"], batch[\"ac\"],\n",
    "                                                                                 batch[\"atarg\"], batch[\"vtarg\"],\n",
    "                                                                                 cur_lrmult, sess=self.sess,\n",
    "                                                                                 options=run_options,\n",
    "                                                                                 run_metadata=run_metadata)\n",
    "                                    writer.add_run_metadata(run_metadata, 'step%d' % steps)\n",
    "                                else:\n",
    "                                    summary, grad, *newlosses = self.lossandgrad(batch[\"ob\"], batch[\"ob\"], batch[\"ac\"],\n",
    "                                                                                 batch[\"atarg\"], batch[\"vtarg\"],\n",
    "                                                                                 cur_lrmult, sess=self.sess)\n",
    "                                writer.add_summary(summary, steps)\n",
    "                            else:\n",
    "                                _, grad, *newlosses = self.lossandgrad(batch[\"ob\"], batch[\"ob\"], batch[\"ac\"],\n",
    "                                                                       batch[\"atarg\"], batch[\"vtarg\"], cur_lrmult,\n",
    "                                                                       sess=self.sess)\n",
    "\n",
    "                            self.adam.update(grad, self.optim_stepsize * cur_lrmult)\n",
    "                            losses.append(newlosses)\n",
    "                        logger.log(fmt_row(13, np.mean(losses, axis=0)))\n",
    "\n",
    "                    logger.log(\"Evaluating losses...\")\n",
    "                    losses = []\n",
    "                    for batch in dataset.iterate_once(optim_batchsize):\n",
    "                        newlosses = self.compute_losses(batch[\"ob\"], batch[\"ob\"], batch[\"ac\"], batch[\"atarg\"],\n",
    "                                                        batch[\"vtarg\"], cur_lrmult, sess=self.sess)\n",
    "                        losses.append(newlosses)\n",
    "                    mean_losses, _, _ = mpi_moments(losses, axis=0)\n",
    "                    logger.log(fmt_row(13, mean_losses))\n",
    "                    for (loss_val, name) in zipsame(mean_losses, self.loss_names):\n",
    "                        logger.record_tabular(\"loss_\" + name, loss_val)\n",
    "                    logger.record_tabular(\"ev_tdlam_before\", explained_variance(vpredbefore, tdlamret))\n",
    "\n",
    "                    # local values\n",
    "                    lrlocal = (seg[\"ep_lens\"], seg[\"ep_rets\"])\n",
    "\n",
    "                    # list of tuples\n",
    "                    listoflrpairs = MPI.COMM_WORLD.allgather(lrlocal)\n",
    "                    lens, rews = map(flatten_lists, zip(*listoflrpairs))\n",
    "                    lenbuffer.extend(lens)\n",
    "                    rewbuffer.extend(rews)\n",
    "                    logger.record_tabular(\"EpLenMean\", np.mean(lenbuffer))\n",
    "                    logger.record_tabular(\"EpRewMean\", np.mean(rewbuffer))\n",
    "                    logger.record_tabular(\"EpThisIter\", len(lens))\n",
    "                    episodes_so_far += len(lens)\n",
    "                    timesteps_so_far += MPI.COMM_WORLD.allreduce(seg[\"total_timestep\"])\n",
    "                    iters_so_far += 1\n",
    "                    logger.record_tabular(\"EpisodesSoFar\", episodes_so_far)\n",
    "                    logger.record_tabular(\"TimestepsSoFar\", timesteps_so_far)\n",
    "                    logger.record_tabular(\"TimeElapsed\", time.time() - t_start)\n",
    "                    if self.verbose >= 1 and MPI.COMM_WORLD.Get_rank() == 0:\n",
    "                        logger.dump_tabular()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def save(self, save_path):\n",
    "        data = {\n",
    "            \"gamma\": self.gamma,\n",
    "            \"timesteps_per_actorbatch\": self.timesteps_per_actorbatch,\n",
    "            \"clip_param\": self.clip_param,\n",
    "            \"entcoeff\": self.entcoeff,\n",
    "            \"optim_epochs\": self.optim_epochs,\n",
    "            \"optim_stepsize\": self.optim_stepsize,\n",
    "            \"optim_batchsize\": self.optim_batchsize,\n",
    "            \"lam\": self.lam,\n",
    "            \"adam_epsilon\": self.adam_epsilon,\n",
    "            \"schedule\": self.schedule,\n",
    "            \"verbose\": self.verbose,\n",
    "            \"policy\": self.policy,\n",
    "            \"observation_space\": self.observation_space,\n",
    "            \"action_space\": self.action_space,\n",
    "            \"n_envs\": self.n_envs,\n",
    "            \"_vectorize_action\": self._vectorize_action\n",
    "        }\n",
    "\n",
    "        params = self.sess.run(self.params)\n",
    "\n",
    "        self._save_to_file(save_path, data=data, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_id, num_timesteps, seed):\n",
    "    rank = MPI.COMM_WORLD.Get_rank()\n",
    "\n",
    "    if rank == 0:\n",
    "        logger.configure()\n",
    "    else:\n",
    "        logger.configure(format_strs=[])\n",
    "    workerseed = seed + 10000 * MPI.COMM_WORLD.Get_rank()\n",
    "    set_global_seeds(workerseed)\n",
    "    env = make_atari(env_id)\n",
    "    \n",
    "    env = bench.Monitor(env, logger.get_dir() and\n",
    "                        os.path.join(logger.get_dir(), str(rank)))\n",
    "    env.seed(workerseed)\n",
    "\n",
    "    env = wrap_deepmind(env)\n",
    "    env.seed(workerseed)\n",
    "    \n",
    "    def callback(_locals, _globals):\n",
    "        global n_steps, best_mean_reward\n",
    "        print(\"Step:\", n_steps)\n",
    "\n",
    "        if (n_steps + 1) % 100 == 0:\n",
    "            _locals['self'].save(\"test_mod_model_{}\".format(env_id))\n",
    "        n_steps += 1\n",
    "\n",
    "    model = PPO1_Mod(CnnPolicy, env, timesteps_per_actorbatch=256, clip_param=0.2, entcoeff=0.01, optim_epochs=4,\n",
    "                 optim_stepsize=1e-3, optim_batchsize=64, gamma=0.99, lam=0.95, schedule='linear', verbose=2,\n",
    "                    tensorboard_log=log_dir)\n",
    "    model.learn(total_timesteps=num_timesteps, callback=callback)\n",
    "    model.save(\"model_{}\".format(env_id))\n",
    "\n",
    "    return model, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /home/ubuntu/ppo_logs/BreakoutNoFrameskip-v4-25\n",
      "Logging to /tmp/openai-2018-12-03-02-34-39-494003\n",
      "Logging to /tmp/openai-2018-12-03-02-34-39-496623\n",
      "Step: 0\n",
      "********** Iteration 0 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00285 |      -0.01384 |       3.89478 |       0.00288 |       1.38353\n",
      "     -0.00598 |      -0.01383 |       0.59409 |       0.00288 |       1.38338\n",
      "     -0.00779 |      -0.01383 |       0.16383 |       0.00358 |       1.38265\n",
      "     -0.00935 |      -0.01381 |       0.13253 |       0.00555 |       1.38072\n",
      "Evaluating losses...\n",
      "     -0.00999 |      -0.01381 |       0.11286 |       0.00558 |       1.38068\n",
      "----------------------------------\n",
      "| EpLenMean       | 52.8         |\n",
      "| EpRewMean       | 1.25         |\n",
      "| EpThisIter      | 4            |\n",
      "| EpisodesSoFar   | 4            |\n",
      "| TimeElapsed     | 3.92         |\n",
      "| TimestepsSoFar  | 256          |\n",
      "| ev_tdlam_before | -0.0116      |\n",
      "| loss_ent        | 1.3806794    |\n",
      "| loss_kl         | 0.005582163  |\n",
      "| loss_pol_entpen | -0.013806794 |\n",
      "| loss_pol_surr   | -0.00998617  |\n",
      "| loss_vf_loss    | 0.112864286  |\n",
      "----------------------------------\n",
      "Step: 1\n",
      "********** Iteration 1 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00056 |      -0.01380 |       0.02850 |      2.70e-05 |       1.38019\n",
      "     -0.00921 |      -0.01375 |       0.02981 |       0.00102 |       1.37542\n",
      "     -0.03276 |      -0.01358 |       0.02251 |       0.00974 |       1.35762\n",
      "     -0.03727 |      -0.01325 |       0.02491 |       0.03204 |       1.32530\n",
      "Evaluating losses...\n",
      "     -0.04052 |      -0.01332 |       0.02294 |       0.02709 |       1.33185\n",
      "----------------------------------\n",
      "| EpLenMean       | 34.1         |\n",
      "| EpRewMean       | 0.667        |\n",
      "| EpThisIter      | 11           |\n",
      "| EpisodesSoFar   | 15           |\n",
      "| TimeElapsed     | 5.45         |\n",
      "| TimestepsSoFar  | 557          |\n",
      "| ev_tdlam_before | -0.0119      |\n",
      "| loss_ent        | 1.3318453    |\n",
      "| loss_kl         | 0.027087895  |\n",
      "| loss_pol_entpen | -0.013318453 |\n",
      "| loss_pol_surr   | -0.04051746  |\n",
      "| loss_vf_loss    | 0.022937424  |\n",
      "----------------------------------\n",
      "Step: 2\n",
      "********** Iteration 2 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00080 |      -0.01332 |       0.02129 |      3.52e-05 |       1.33240\n",
      "     -0.00666 |      -0.01317 |       0.02198 |       0.00137 |       1.31686\n",
      "     -0.02052 |      -0.01263 |       0.02153 |       0.01677 |       1.26332\n",
      "     -0.01818 |      -0.01233 |       0.02191 |       0.03099 |       1.23267\n",
      "Evaluating losses...\n",
      "     -0.02132 |      -0.01247 |       0.02135 |       0.02436 |       1.24677\n",
      "----------------------------------\n",
      "| EpLenMean       | 29.3         |\n",
      "| EpRewMean       | 0.5          |\n",
      "| EpThisIter      | 11           |\n",
      "| EpisodesSoFar   | 26           |\n",
      "| TimeElapsed     | 6.95         |\n",
      "| TimestepsSoFar  | 814          |\n",
      "| ev_tdlam_before | -0.00974     |\n",
      "| loss_ent        | 1.2467709    |\n",
      "| loss_kl         | 0.024360651  |\n",
      "| loss_pol_entpen | -0.012467708 |\n",
      "| loss_pol_surr   | -0.021317948 |\n",
      "| loss_vf_loss    | 0.021346323  |\n",
      "----------------------------------\n",
      "Step: 3\n",
      "********** Iteration 3 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00277 |      -0.01242 |       0.20249 |       0.00021 |       1.24235\n",
      "     -0.01647 |      -0.01202 |       0.18962 |       0.00565 |       1.20222\n",
      "     -0.01906 |      -0.01194 |       0.16538 |       0.01324 |       1.19363\n",
      "     -0.01796 |      -0.01198 |       0.17266 |       0.01825 |       1.19796\n",
      "Evaluating losses...\n",
      "     -0.01815 |      -0.01191 |       0.15822 |       0.02022 |       1.19080\n",
      "----------------------------------\n",
      "| EpLenMean       | 30.8         |\n",
      "| EpRewMean       | 0.614        |\n",
      "| EpThisIter      | 7            |\n",
      "| EpisodesSoFar   | 33           |\n",
      "| TimeElapsed     | 8.45         |\n",
      "| TimestepsSoFar  | 1076         |\n",
      "| ev_tdlam_before | 0.00756      |\n",
      "| loss_ent        | 1.1907969    |\n",
      "| loss_kl         | 0.020219326  |\n",
      "| loss_pol_entpen | -0.011907969 |\n",
      "| loss_pol_surr   | -0.018154519 |\n",
      "| loss_vf_loss    | 0.15822303   |\n",
      "----------------------------------\n",
      "Step: 4\n",
      "********** Iteration 4 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00550 |      -0.01155 |       0.15516 |       0.00250 |       1.15543\n",
      "     -0.00501 |      -0.01084 |       0.17397 |       0.01547 |       1.08380\n",
      "      0.00238 |      -0.01206 |       0.16012 |       0.00396 |       1.20608\n",
      "     -0.01154 |      -0.01185 |       0.14966 |       0.00588 |       1.18467\n",
      "Evaluating losses...\n",
      "     -0.01404 |      -0.01099 |       0.14294 |       0.01853 |       1.09932\n",
      "----------------------------------\n",
      "| EpLenMean       | 31.8         |\n",
      "| EpRewMean       | 0.738        |\n",
      "| EpThisIter      | 7            |\n",
      "| EpisodesSoFar   | 40           |\n",
      "| TimeElapsed     | 9.94         |\n",
      "| TimestepsSoFar  | 1341         |\n",
      "| ev_tdlam_before | -0.00247     |\n",
      "| loss_ent        | 1.0993161    |\n",
      "| loss_kl         | 0.01852917   |\n",
      "| loss_pol_entpen | -0.010993162 |\n",
      "| loss_pol_surr   | -0.014037618 |\n",
      "| loss_vf_loss    | 0.1429419    |\n",
      "----------------------------------\n",
      "Step: 5\n",
      "********** Iteration 5 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00053 |      -0.01046 |       0.16785 |       0.00391 |       1.04600\n",
      "     -0.00045 |      -0.01028 |       0.15183 |       0.00514 |       1.02765\n",
      "     -0.00153 |      -0.01039 |       0.15919 |       0.00385 |       1.03931\n",
      "     -0.00363 |      -0.01055 |       0.15076 |       0.00453 |       1.05524\n",
      "Evaluating losses...\n",
      "     -0.00910 |      -0.01095 |       0.14761 |       0.00492 |       1.09533\n",
      "----------------------------------\n",
      "| EpLenMean       | 30.6         |\n",
      "| EpRewMean       | 0.785        |\n",
      "| EpThisIter      | 10           |\n",
      "| EpisodesSoFar   | 50           |\n",
      "| TimeElapsed     | 11.4         |\n",
      "| TimestepsSoFar  | 1605         |\n",
      "| ev_tdlam_before | 0.00513      |\n",
      "| loss_ent        | 1.095334     |\n",
      "| loss_kl         | 0.0049209343 |\n",
      "| loss_pol_entpen | -0.010953341 |\n",
      "| loss_pol_surr   | -0.009097681 |\n",
      "| loss_vf_loss    | 0.14760919   |\n",
      "----------------------------------\n",
      "Step: 6\n",
      "********** Iteration 6 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "     -0.00578 |      -0.01040 |       0.40208 |       0.00833 |       1.04023\n",
      "     -0.01456 |      -0.00926 |       0.34934 |       0.03538 |       0.92624\n",
      "     -0.01940 |      -0.01024 |       0.32491 |       0.00895 |       1.02354\n",
      "     -0.01415 |      -0.00944 |       0.29452 |       0.03423 |       0.94431\n",
      "Evaluating losses...\n",
      "     -0.01872 |      -0.00953 |       0.29072 |       0.03178 |       0.95294\n",
      "----------------------------------\n",
      "| EpLenMean       | 31.1         |\n",
      "| EpRewMean       | 0.847        |\n",
      "| EpThisIter      | 4            |\n",
      "| EpisodesSoFar   | 54           |\n",
      "| TimeElapsed     | 12.9         |\n",
      "| TimestepsSoFar  | 1867         |\n",
      "| ev_tdlam_before | -0.0242      |\n",
      "| loss_ent        | 0.9529382    |\n",
      "| loss_kl         | 0.031778947  |\n",
      "| loss_pol_entpen | -0.009529382 |\n",
      "| loss_pol_surr   | -0.018719371 |\n",
      "| loss_vf_loss    | 0.29072145   |\n",
      "----------------------------------\n",
      "Step: 7\n",
      "********** Iteration 7 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "      0.00248 |      -0.00977 |       0.49960 |       0.00130 |       0.97693\n",
      "      0.00168 |      -0.01031 |       0.49807 |       0.00797 |       1.03128\n"
     ]
    }
   ],
   "source": [
    "env_id='BreakoutNoFrameskip-v4'\n",
    "num_timesteps=20000000\n",
    "seed=343\n",
    "best_mean_reward, n_steps = -np.inf, 0\n",
    "\n",
    "base_dir = home + '/ppo_logs'\n",
    "prev = [f for f in os.listdir(base_dir) if env_id in f]\n",
    "log_dir = base_dir + '/{}-{}'.format(env_id, len(prev))\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "print('Logging to {}'.format(log_dir))\n",
    "\n",
    "logger.configure()\n",
    "model, env = train(env_id, num_timesteps, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADmJJREFUeJzt3X/sVfV9x/Hna1j9g3YBqyNGcICjXXDZqCWOZGq6uVokTdH94SBLpZsZmmjSRpcFa7KRJU22rmLSbLPBSIqLBd2s1SzWyVhTs2xYwVIUFQWLkW8Qpi7qsKkF3vvjfL7r8cv38r3f+z6399zr65Hc3HM/9/z4nPh9+Tn3w7nvq4jAzHr3S4PugNmwc4jMkhwisySHyCzJITJLcojMkvoWIknLJe2TtF/Sun4dx2zQ1I9/J5I0A3gR+DRwCHgKWB0RzzV+MLMB69dIdAmwPyJejoj3gK3Ayj4dy2ygzujTfs8HXq29PgT8dqeVJfm2CWuj1yPi3KlW6leIpiRpLbB2UMc368Ir3azUrxCNAfNqr+eWtv8XERuBjeCRyIZbvz4TPQUskrRA0pnAKuCRPh3LbKD6MhJFxHFJNwP/CswANkXE3n4cy2zQ+jLFPe1OtPBybsOGDdPe5pZbbkntY+L2Te0ja2IfpjrPfvRhun1qyK6IWDrVSr5jwSxpYLNzw6Yfo8QgRjtrnkcisySPRDZtHv3ezyORWZJHIpvSVDNfH/SRySORWZJHoi418X/btuzDmuWRyCzJITJL8m0/Zp35th+zX4RWTCzMnTv3F3LTotl0dPs36ZHILMkhMktyiMySHCKzpJ5DJGmepO9Jek7SXklfLO3rJY1J2l0eK5rrrln7ZGbnjgO3RsTTkj4C7JK0rbx3Z0R8Ld89s/brOUQRcRg4XJbfkfQ8VdFGsw+URj4TSZoPfAJ4sjTdLGmPpE2SZjdxDLO2SodI0oeBB4EvRcTbwF3AhcASqpHqjg7brZW0U9LOY8eOZbthNjCpEEn6EFWA7ouIbwNExJGIOBERJ4G7qYrbnyIiNkbE0ohYOnPmzEw3zAYqMzsn4B7g+YjYUGs/r7baNcCzvXfPrP0ys3O/A3weeEbS7tL2ZWC1pCVAAAeBG1I9NGu5zOzcfwCa5K1He++O2fDxHQtmSa34KsRU/DUJ64em6lV4JDJLcojMkhwisySHyCzJITJLcojMkhwisySHyCzJITJLcojMkhwisySHyCzJITJLcojMkhwis6T094kkHQTeAU4AxyNiqaSzgfuB+VRfEb82Iv4neyyzNmpqJPrdiFhS+1WxdcD2iFgEbC+vzUZSvy7nVgKby/Jm4Oo+Hcds4JoIUQCPS9olaW1pm1PKDAO8Bsxp4DhmrdREjYVLI2JM0q8A2yS9UH8zImKyHzYugVsLMHu2Kw3b8EqPRBExVp6PAg9RVTw9Ml7EsTwfnWQ7V0C1kZAtIzyz/KwKkmYCV1JVPH0EWFNWWwM8nDmOWZtlL+fmAA9VFYU5A/hWRDwm6SngAUnXA68A1yaPY9ZaqRBFxMvAb03S/gZwRWbfZsPCdyyYJQ1FBdQdy5cPugs2gv6zof14JDJLcojMkhwisySHyCzJITJLGorZuZO/9vagu2DWkUcisySHyCzJITJLcojMkhwisySHyCxpKKa43/zldwfdBbOOPBKZJTlEZkk9X85J+jhVldNxC4G/AGYBfwr8d2n/ckQ82nMPzVqu5xBFxD5gCYCkGcAYVbWfPwbujIivNdJDs5Zr6nLuCuBARLzS0P7MhkZTs3OrgC211zdLug7YCdyaLWb/5q+/l9ncbHKvN7Ob9Egk6Uzgc8A/laa7gAupLvUOA3d02G6tpJ2Sdh47dizbDbOBaeJy7irg6Yg4AhARRyLiREScBO6mqoh6CldAtVHRRIhWU7uUGy8fXFxDVRHVbGSlPhOV0sGfBm6oNX9V0hKqX4s4OOE9s5GTrYB6DPjohLbPp3pkNmSG4t65b528YNBdsBF0ZUP78W0/ZkkOkVmSQ2SW5BCZJTlEZklDMTv33tb1g+6CjaIrm/lxFY9EZkkOkVmSQ2SW5BCZJTlEZkkOkVnSUExx//tjywbdBRtBn71yQyP78UhkluQQmSU5RGZJXYVI0iZJRyU9W2s7W9I2SS+V59mlXZK+Lmm/pD2SLu5X583aoNuR6JvA8glt64DtEbEI2F5eQ1X9Z1F5rKUqoWU2sroKUUQ8Abw5oXklsLksbwaurrXfG5UdwKwJFYDMRkrmM9GciDhcll8D5pTl84FXa+sdKm3v4+KNNioamViIiKAqkTWdbVy80UZCJkRHxi/TyvPR0j4GzKutN7e0mY2kTIgeAdaU5TXAw7X268os3TLgrdpln9nI6eq2H0lbgE8B50g6BPwl8NfAA5KuB14Bri2rPwqsAPYD71L9XpHZyOoqRBGxusNbV0yybgA3ZTplNkx8x4JZkkNkluQQmSU5RGZJDpFZkkNkluQQmSU5RGZJDpFZkkNkluQQmSU5RGZJDpFZkkNkluQQmSU5RGZJDpFZ0pQh6lD99G8lvVAqnD4kaVZpny/pJ5J2l8c3+tl5szboZiT6JqdWP90G/EZE/CbwInBb7b0DEbGkPG5spptm7TVliCarfhoRj0fE8fJyB1VZLLMPpCY+E/0J8N3a6wWSfijp+5Iu67SRK6DaqEj9Up6k24HjwH2l6TBwQUS8IemTwHckXRQRb0/cNiI2AhsB5s2bN63qqWZt0vNIJOkLwGeBPyplsoiIn0bEG2V5F3AA+FgD/TRrrZ5CJGk58OfA5yLi3Vr7uZJmlOWFVD+v8nITHTVrqykv5zpUP70NOAvYJglgR5mJuxz4K0k/A04CN0bExJ9kMRspU4aoQ/XTezqs+yDwYLZTZsPEdyyYJTlEZkkOkVmSQ2SW5BCZJTlEZkkOkVmSQ2SW5BCZJTlEZkkOkVmSQ2SW5BCZJTlEZkkOkVmSQ2SW5BCZJfVaAXW9pLFapdMVtfduk7Rf0j5Jn+lXx83aotcKqAB31iqdPgogaTGwCriobPMP44VLzEZVTxVQT2MlsLWUzvoxsB+4JNE/s9bLfCa6uRS03yRpdmk7H3i1ts6h0nYKV0C1UdFriO4CLgSWUFU9vWO6O4iIjRGxNCKWzpw5s8dumA1eTyGKiCMRcSIiTgJ38/NLtjFgXm3VuaXNbGT1WgH1vNrLa4DxmbtHgFWSzpK0gKoC6g9yXTRrt14roH5K0hIggIPADQARsVfSA8BzVIXub4qIE/3pulk7NFoBtaz/FeArmU6ZDRPfsWCW5BCZJTlEZkkOkVmSQ2SW5BCZJTlEZkkOkVmSQ2SW5BCZJTlEZkkOkVmSQ2SW5BCZJTlEZkkOkVlSr8Ub768VbjwoaXdpny/pJ7X3vtHPzpu1wZTfbKUq3vh3wL3jDRHxh+PLku4A3qqtfyAiljTVQbO26+br4U9Imj/Ze5IEXAv8XrPdMhse2c9ElwFHIuKlWtsCST+U9H1JlyX3b9Z63VzOnc5qYEvt9WHggoh4Q9Inge9Iuigi3p64oaS1wFqA2bNnT3zbbGj0PBJJOgP4A+D+8bZSg/uNsrwLOAB8bLLtXQHVRkXmcu73gRci4tB4g6Rzx38FQtJCquKNL+e6aNZu3UxxbwH+C/i4pEOSri9vreL9l3IAlwN7ypT3PwM3RkS3vyhhNpR6Ld5IRHxhkrYHgQfz3TIbHr5jwSzJITJLcojMkhwisySHyCzJITJLcojMkhwisySHyCwpexd3I96acZJ/mfW/g+6GDZEdy5fnd/L44/l94JHILM0hMktyiMySWvGZyGy6lj32WHofjXyuwiORWZpHIvvAamI0A1BENLKjVCekwXfC7FS7ImLpVCt18/XweZK+J+k5SXslfbG0ny1pm6SXyvPs0i5JX5e0X9IeSRfnz8Wsvbr5THQcuDUiFgPLgJskLQbWAdsjYhGwvbwGuIqqQMkiqpJYdzXea7MWmTJEEXE4Ip4uy+8AzwPnAyuBzWW1zcDVZXklcG9UdgCzJJ3XeM/NWmJas3OlnPAngCeBORFxuLz1GjCnLJ8PvFrb7FBpMxtJXc/OSfowVSWfL0XE21UZ7kpExHQnB+oVUM2GWVcjkaQPUQXovoj4dmk+Mn6ZVp6PlvYxYF5t87ml7X3qFVB77bxZG3QzOyfgHuD5iNhQe+sRYE1ZXgM8XGu/rszSLQPeql32mY2eiDjtA7gUCGAPsLs8VgAfpZqVewn4N+Dssr6Av6eqw/0MsLSLY4QffrTwsXOqv92I8D+2mp1GM//Yaman5xCZJTlEZkkOkVmSQ2SW1JbvE70OHCvPo+IcRud8RulcoPvz+dVudtaKKW4ASTtH6e6FUTqfUToXaP58fDlnluQQmSW1KUQbB92Bho3S+YzSuUDD59Oaz0Rmw6pNI5HZUBp4iCQtl7SvFDZZN/UW7SPpoKRnJO2WtLO0TVrIpY0kbZJ0VNKztbahLUTT4XzWSxor/412S1pRe++2cj77JH1m2gfs5lbvfj2AGVRfmVgInAn8CFg8yD71eB4HgXMmtH0VWFeW1wF/M+h+nqb/lwMXA89O1X+qr8F8l+orL8uAJwfd/y7PZz3wZ5Osu7j83Z0FLCh/jzOmc7xBj0SXAPsj4uWIeA/YSlXoZBR0KuTSOhHxBPDmhOahLUTT4Xw6WQlsjYifRsSPgf1Uf5ddG3SIRqWoSQCPS9pVakdA50Iuw2IUC9HcXC5BN9Uur9PnM+gQjYpLI+Jiqpp7N0m6vP5mVNcNQzsNOuz9L+4CLgSWAIeBO5ra8aBD1FVRk7aLiLHyfBR4iOpyoFMhl2GRKkTTNhFxJCJORMRJ4G5+fsmWPp9Bh+gpYJGkBZLOBFZRFToZGpJmSvrI+DJwJfAsnQu5DIuRKkQz4XPbNVT/jaA6n1WSzpK0gKpy7w+mtfMWzKSsAF6kmhW5fdD96aH/C6lmd34E7B0/BzoUcmnjA9hCdYnzM6rPBNd36j89FKJpyfn8Y+nvnhKc82rr317OZx9w1XSP5zsWzJIGfTlnNvQcIrMkh8gsySEyS3KIzJIcIrMkh8gsySEyS/o/Gy5aBV7xJJoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0\n",
      "Iters : 105\n"
     ]
    }
   ],
   "source": [
    "model = PPO1_Mod.load('mod_3_model_' + env_id)\n",
    "\n",
    "env = make_atari(env_id)\n",
    "env = wrap_deepmind(env)\n",
    "env.reset()\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "count = 0\n",
    "frames = []\n",
    "level_count = 5\n",
    "\n",
    "taken = []\n",
    "while True:\n",
    "    actions = model.step(np.array([obs]))\n",
    "    obs, reward, done, info = env.step(actions[0])\n",
    "    taken.append(actions[0])\n",
    "    total_reward += reward\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    d = env.render(mode='rgb_array')\n",
    "    plt.imshow(d)\n",
    "    plt.show()\n",
    "    frames.append(d)\n",
    "        \n",
    "    count += 1\n",
    "    if count > 100:\n",
    "        done = True\n",
    "    if done:\n",
    "        print(\"Reward:\", total_reward)\n",
    "        print(\"Iters :\", count)\n",
    "        level_count -= 1\n",
    "        if level_count < 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa4a594ea90>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsvXu0ZVdZJ/qb67nXWrsqj6rKA5IikAQTwts0HUAFRBEF21bx1dpeHXq5og51oPi6il5Fr63dtAq3QVrsq+31hQ8edhBRQCBqQoiEZ4QkPBMIqSRVdfZea6/nvH/M91xz7b1Ppc6ppMb8jVGj9tlnnTXnmmvOb37f73tMQimFh4eHh8fZheBMd8DDw8PD4/TDC3cPDw+PsxBeuHt4eHichfDC3cPDw+MshBfuHh4eHmchvHD38PDwOAvhhbuHh4fHWQgv3D08PDzOQnjh7uHh4XEWIjpTDR8+fJhedtllZ6p5Dw8Pj4cl3v/+9x+jlB7ZdN0ZE+6XXXYZbr755jPVvIeHh8fDEoSQT29znadlPDw8PM5CeOHu4eHhcRbCC3cPDw+PsxBeuHt4eHichfDC3cPDw+MsxEbhTgiZEUJuIoTcSgj5CCHk/3JckxJC/pQQcjsh5EZCyGV70VkPDw8Pj+2wjeZeA/hKSumTADwZwPMJIddZ13wfgAcopVcA+K8A/tPp7aaHh4eHx26wMc6dsnP4FvzHmP+zz+b7BgC/yD//OYBXE0II3ccz/O65+9O46T1vwyfOe9bkNYeXH8dTLkrwhKd/jfH9be/5Kxw5/i84VKTG9x+7Z4n3Fs/DzuxiRGGA73jaURyZJ8AH/xS4+uuBpJDXNt2AN37gLrzoqZcgCIj8/t6dGn9802fQ9QMOrD6PL1v+La6+sMAIR/8tcMVX4cN3nUA3UDz50nOBz9wIJDlw0RPwjtvuwQc+cxwAcNkD/4j7skdjZ3axcYsnfuEvMG+OAQC6IMEHLvoWNNEceRrhe55xGWZxuHkgj38W+OJHgcd+DT5xzw7ecuvdfOxuR9IvcffBJ22+h4Vr7nkzzqk/P/q+DWb4l4u/FV2YYT6L8D3PeDSSbge46b8DXY2y6fBPx2a49YJ/z577cIFveuolxj1u+8JJXP/B8b0v3vkQuiDFvcVjAQBf+4SLcfXFB82Lbv1T4L7bAQAfvvsEFqtuoo/fhi6cGd8fmqf47qc/CoSQ0d8AwO1fXODNt94N8CVw7WXn4yseO5138oG//xOsPnkTAICSAEef83145GOuNi/64BuAxz4PND2IP3//5/D1T3oEZgEFbv1j4Mn/AYuW4vf/8VOo2974s3n9RTxz8VZcI+bdhY8DrvlG3HnvAl84scIzrjgMfOHDQLNk81DHp24A8vOBC67G2z7yBXzkrhOjvj/xi2/G0w+XKBIlTiil+OgXdnDVhQcQBgRIDwDXvQQIY3mNvjZsPO4RB/H8x5vzG5+/Fehb4JJrze8/+R5gfiFw5LG4/kOfx22fPwkAuPy+d+HzBx6PMjmMKAzwnf/2KA4VCRuva74RiDN1j64GPvQG4MnfieNViz/850+j6cb9cuGCxW34iuEmHD0/Z19c8Vzg6HV47yeO4aZP3gcAeMz978ZFi4/Jvymu/DI84VnftNX9TxVbJTERQkIA7wdwBYD/h1J6o3XJIwF8FgAopR0h5ASAQwCOWfd5MYAXA8DRo0cfXM8t3Pm21+AFn3otrm7+Bxokzmt+N/ovyJKTgCXci3f8LA7RuwGohUoBXA2Kt3d34be7b2XXpRG+7+oB+Kv/g137pG+T199w+zH85J9/EFdeMMdTjp4nv3/TB+7CK9/+cQDAj0d/hqujN4L+K4EpEihw/uXAj9yCX3vrbSibDn/5g88Erv8J4OAjgP/wp/j5N34Edx2vQAjwoeSn8Sf9V+JV/XfJO1yAB/DS1DSY/uSOGH/dMyPrCY88B8+84vDmgbzpdezfz92D//6eO/FnN38OhACvjV6Jo+SL+Jn21zbfQ8McJT6UvgIAMFD11AFhQu9/3pHib3u2WJ9y9Dz8m513AO/4ZQBADuC5AH7yw5fiPpwDQoAXPvERSCJlcL7mXXfgTR+4G7aM/av4V3Ecc7y8/SlQCnzqvhK//R1PURf0LX+PFBQEj3OoIaKPv3v7HO+malMTKstzvuQCHD2UO5/79e/9JP74ps+AEHb95UcK/P2PP3tynB7xnp/BBbgfAyUICMU/v22BR77kteqCE3cBf/n9wNf/Fm57xDfhZX/+QRyYRXh+8QngzT8MnP9o/MPJy/Ebb/tXADDG4weDN+Ka+M/4vKNAnAPXfCP+27vuwD/dcR9u+OmvBN7xCuDk54AfeK/Zsbf8KHDxk4AXvR4/85cfwv3Lxrj3AbrAB2evAG4HYM3qqylAPgFIXfDodcClT1O3vvVuuTb0e1IKnF8kY+H+d78IrE4C//vfm9+/6QeBo88Avul38LI33Ipl0yMhHW5Lfgr/tX8RXtV9IwDg3DzGd1++At74EiBKgcd/s7rH7X8HvOmHgIuegLd97jz8578d92sKr4lehaPh+/jzU+DTNwDfez1+6a8/go/fswAhwI3JK3ABOS7XwI1DCzwUhDultAfwZELIuQD+ihDyeErph3fbGKX0dQBeBwDXXnvt6dXqmx0EhOJff/5ZTNNw4Pb/9GuYrcrR9xkt8a75C/Dsn/gj+d2y7jD86iV4zmUZfvB7vxZX/J9vxbLugJobMfVJ4x47NdP6FrWp/S1rpkXd8atfh4/+3ltw8rM5wp/9LIpUG/o3/wjw8b+R96kafo96h/3j9/2eZ1yGX3zhVcAvrfD9TzuM7/93L1D3OPYJ4NUAvul32SL6zcfj1d98JV5y0ZfhBb/93lG/JlHvAN0K6Bos6x5XXDDH3730WcDvvxZ4APjkj71g8z10nLwbeCWAr/8tBF/6Per7++4AXvVUvO5br8K/nPcMfON/+0fWR/68eOltePv1f4avvu3l+MeXPg1/+PEQv/zXH0XV9IZwX9YdHnfxQVz/o19utvvqXwSyGT75fS/AC377Pezd6WiWACjwNb+Kzz72e/EVv/FO/JdveRK++Us1y+CejwKveTp+/zuvBq5Rz/03H/4CfuAP3792TJd1h0cfLvDOn3g2fvLPb8W7P35s8loAyGiFf77w23DdD74Ox37xUSDt0rxAjEu9I9vdWXVApL4Xz/jen3oOLjlPbTof/v23o74zwuJld+PQzb8JvOtXgaHHYtVhZ9Wq+4s27Hb7GgCbgz/wrMvx0197lfx1/8BngN8C3n7Fz+Grv+tl8vsbPnEM3/X6G/Fb3/5kfMP5nwN+73mj+4v+fuJXvhZxqN7pL73lo3jDzZ9192Wqj/UOhoFi2fT4kedeiZc+8zDw6xQ//hUX44ee83xc9fN/Y84v+z7G+DIL79ZfeB7OyWJswsd/45X4YHkVnvgLNwJ/9O3Aybv48/V40Zdegv/8LU8CfqUFrv1hBF/zKwCAp2+864PHrqJlKKXHAbwTwPOtX90F4FIAIIREAM4BcN/p6OC2CFoutJvF5DUZrTCjleP7FRbU1PbLukOFFDOsEIUBkjDAsum4UID6X7seUMJcft90SKIAYUCQ0RVKpOw+OpJC3q+sO3WPZimfp2w6ZEkIyOe0Fr947iRXdFGzRM5N5dJucwrivu0Sy6ZDnoRaX5bTf7fpfrFFRcW57LfsY92r65Mcy4G9k6QvZT/ssVvWveqj3S6/V56E4zGX/crl70b3SXLzWg5x3boxLZsOGafB8iQat6+BDgNyrED5mNQkRdhZSog274RQLJve/F4+h6mzzYYVKqTseu2Zlk3HvgPY/HG932YJDD26fkDTDaMxCvl8XFKT0hR9sds0r+kRh8QQ7AAQhQTd4ND9puYgXycVp6PyJDTGJY0CECLm18LZF/17sZad88qBjFZYCvmR5PLecv0MA9Au1ZzfJ2wTLXOEa+wghGQAvhrAbdZlbwbwv/HPLwLwjv3k2wFduI81c4GU1pjR2viODgMy1FgM5uQsmx5LOsOMrgAAeRqianp1/7YcXQ8AVduNvi/4JEnpCks6Y/fRIYQ7pSibXk5StCXQlGi6AW1P2X2aiecUPyeFIdwLKYisNqegjWPZaIKzKdeO7SSksLaEu/i5LU1hKdqPC+xwgUHaSrvG2jzbHnnqMEAN4R6Nx1y0k8zlPUf3Seb8XuZzF+nmMS2bXl6XJ2zuTC2Juq4QEirHpCbZWLi3SliJZ7GFu3wOSyjNsMISMy5o1bhXTY9uoIxbbh3vl1LW7tChbN33Fv3aGUzlyOij1qZ5TTfaiAAgDAj6KeFuWzR9C/QN0Jby+QtdCWpLEEJQJBH7/ZScaJTSVLY9kjAYbTpTSGmNHSE/kkK2wdZPBHSV+t0+YpveXwzgnYSQDwJ4H4C3U0r/mhDyS4SQf8eveT2AQ4SQ2wG8FMBP7013pyEXwxrtMh0qpiENylGyqpYICMXJ3pycy4Zp7unAXkweh0yjntj5hRZna+5LbQKnQ4kK6egatqNToK1QNh3TzCiVAkoslCyJtPYtC0XXkMMEIEx7yYRQtNucgq7B6IuvWbJJOmx5H7tfiaW1GNaFJiybBRCmQBhhp0tkn6YskLLukLscxSPN3eq3ZumUU5q7Zl3oyOLN1tCy6dn74vftBorG4TgEgGrBKD7Cx6QJMsT9Gs1dCs7OEu4dAgKkkbmsk6FCRbnFGBfT92mXTMsU6FYAHZhwr4Vwt4Qxb3/HsX4AbtHKNhfWNW6rKwoIusExVi7N3Xp+wL1OsiS0xmti/XDNPdtSaweAlFZY0JQ5hmOmqBmWzpSCs8fYJlrmgwCe4vj+5drnFYBvOb1d2x2inu+O9s6uIRkqBIRitSoxy5lWVi1PIoNb86BIkQxMc8+SkGnlE7SI1NwtIVI1vZwoycBombB10DKA1D7qbkDflAjBNKey1YRPu5DXGmg1IUoI0zrbUhOK2wp3ofEwTVBOcnH/tmSRD9tC08QNBCET4gZ1xC0jvhGcFO/E0O5t2sshIPoWGFrZdsY1Z+dzxjnKFd887U0izgCQ0VhP9UVH1XS4+OCMtx/x73qk0VhorEom3MOUjVEbzpD0Fn3YqPGvdMqjNd9XkUSjCJ5kqFAiZWOgUST6fc4V9+8qbePl9x666Q2QX2MrR1Jzb/U2bc3dLdwDQjBQFnFjPEtbMi2974AwUt/x5zEsF8vCzZPQtHSm1k9buufUGiQ92zzLtsdBTssY46VRgPuJsyZDVQr3KeqAUsRcUFdL5UxZlUxYHu8szr3pUdKZvG+RRkr4AJO0jEv4CGokHiqUdDYWCnwx9fUCNQ+/qsod+TzrJq2ETssAkvsLA4I0CuQGsRGa2VppfZ9sdxPWaS3chJ3FjBOtBC3D6RApMBol3EebZ9sjT22Bo/lFKOUmufX8Gi0j7lnYtAwhnDKzhPuWtIy4bhM11vA5GMzYc3dhLpWKUX81IWbSMqWhSOiI+xVKBy1j3MdFVwiBNwyTlI+45riD1gT4+xJCbbRm3LRMxEOJDWpmGIyNTEJbj0YfW3Od5rukZXYj3KOhwhKcbk0KgPaoqkq2q+baQ4+WeVggGYRwn3Co9g0CyhZ4tVSRLjXXmo53ple8bDqUSBFx8ziLw7UOmVJqQTbnrky8sCuZQ9VJywArrV+rBY8nHlpUpTZRJh1CluMyVo6dPAlPiZZZ1nzxDb3iDdc4rN33m6BlAOlrIIQw2kvQMnw8Hmhj2aYQAmOHqkNAyLFhVNcmWmbSoQrwcTSfeRsnta79SWps4vq6Yht5NOObfJQhtR3/W9AykzRHX6KkKbteo0ikcF9VTCPm34/aHDpNcLrH+nhrfr+UNGXHrLQoc9Iyrs0oDJlwN5yq+sagz32LRpR9tGiZfJe0jGvTcWIYEPcVp1vV+FbLE7LdM0XLnDXCXXDjI3NLQJsQTaU094ZryDtDaiQtlE2PEjNEnaa5b0HLuDV3NlGivkKJ2cjpKjTVulT9qks1+Vb8e9NRZAn31ppAmmNHai3bQKNlKqHB6GM6Nb5T0DTkEbQooVy3jPgzPNCtp2X6gaJ2RHDY/c2TCE03mJqgZulUU1qp6KP1zIK+Wa+5d/K9FxuosUYKdxaC18cFUmpp7lvQMpMOyq4aae5UE4b6XDOFqIOWGVlJ7JoH2jW0DOC0gAzLUINTc3f1S/++LVHWLKxzX2kZLh+WNDXGV4ypF+6nAXIxTNEG2stsKjWZW76wSpoaJj+jZVIE/OVlcnK4aZlqQrjrpnLQVlyDsmmZfNQv8/OO7MNUKCbrF1FZd7rgFP6CbcCfq1st0fbUnJyynV1gHd8Y59oGFDKh1SyVcG8UJeSiZaqpCA6jv7rDVhsDzRcwqZUCTqEUBgSzOBjz+Bz9QLFqB/neN3H03Yr1N8nYBkijHJkt3J20TGdprhMcdleqecfnWlstIGSnsF7ZfVy0TDe9AfJrHhhZvpYPKslHa2aKlgkDJpYMzV1/py5aBkBTqflurxMRsTRNy2jRSLuhZUQIs9w8xVre4e1qtIzn3E8NMwjhPkEb6Jq7NpnFwiqRGry0oGVEMkm+gZZZTtAyeqw4aZesnQlaRu+X8bkSWkCk2u1WZuRKw+NohQPKomVGVJALIkIHatPL9DaBU6RltE1Hh7YBZYKW0eKBFy3QkmSSlhHxyNkkLcM+Zy7hatEyIhdhBActA6yPXbc3nU20TLdiYy2EO+IcOakx9Nb75f+bnLsSVlM0h5p3ijZoDQVHp2JctEwvqaA8Ho/1gADHa3PsSp2WAXgUycK6ZoKW4bfqp4T7xHw0Baqpocv3NUnLqM3TSfVNgd+vsmgvwQhkXnN/cKDDgEzEr29BywiBDgAdzziVOy+HcKgSLkSZQ3WalpnS3GWsa9+B9PWEQ3U+6le7GlsXaymSdmlOHouWmdIyDbQVRKp4u3JQQXab26DlNIsrj1sT7kUaqTwC/hxV26MJcsvpar4j2Ue7Te2zMy5dWDpRNkkPyD46nlma+Q4Y3C+Uo3bq+oG/97Q4qNoEsKocgrYt5f0NTZTTNYVDKJGmRE0yHrnChbs+v1ZTtAxvk/aSCnLRMk2QoWrN0EWV9zFNy5QT4x7y+PJd0TIAOv4ceRoawhqUKs19C1pmKorHCZHEpTtUtb4UqRfuDwpNs0JM+CSainNvxgIdAAb+EkpqatRV06MJeLGothzTMiPNfRwKSSlVE4VPniaYjTU4YSpri6zXBL34PKZILPNUd1patMy6DEnX/cRGk61rcxtoDtIRLFpGOrz4cyzrDm04g+50tTdg8bejNrXPIi7dKEEgLJ0g4FmuE5qaNo461jmpVUw419wFRz9x/cDnY5azEFPCQyJLLarLTi4DuBWjOQ6dtEzXAEOLNsyMyJV+pe7dGZuIQ3AOndLcHbRMF7KNQ0/Skn0UY65lbqprurHVhQnOXX+nrXs+toKWibU5S3ugq9Ua2EjLLCYd004IzR0pGyM+d+VGE3ta5kFhpS+CKeGj7dSDJkQHyZmlhtBdNh36SMUE5zFLRBELcYpz14Vo0w/oBsFbs+v7KBtrcPylD9qm02u1L/raQcvYz9oszVhynfJwxXm7oC0aMUZr29wG9qajQ1vwmRDcLXsO4Szto0x7DjOk0UhasdvUPku+Xq+W2KpNpGrXJK3EY6Ek+9JOae6mINxYroD3d1Zw4S6ccq553SwkHWVkTIuMYluz5u+0DzMeuRIAUYa+1t51vYmWUdEyMztOv1miizL5vtQYaH0E2NzU5lfba1nXFgQ9ZiQyNQ6Lwvo81DtIwgBRGJgbQFsiSyKs2gG0Vpuh+RxmCLBr03FCyA+aMuuGr8F+pZKnvOb+IFCVDg3HhjEJ1Gcqd96ZsVjLpkenC3duWg9ykS1VeUA4JrP2WXeqdFE+ScsMtbuPQ80qy83iYHtaRtOKi22jZbQFJBb/6aFlHJEyAPuet1lY0TJCEPeRokWK1K25nzItw8drih5gfXTTMoVwADtQtRO0zMRmQNslWhoiSZilGPF496bSHZ1KE22bWj2PHi3iclA22rzTKJKpueakZYaOR+KERjlrcX+hBLkos6loGfF716a6OVrG3d+hXqrNzdoMxPuV63dEy7CfabNE0w/T88GGKDVgRSOJdiQtEyZGueP9wFkh3OulYxHYaHSBbmonDQ3RIjLM5rLuQaNMXiO0L7nz8xhqgaVDczdMWd4mjfKxBhclQBCB6puOtQHlcciy9dZp7jYtw/0F2SnQMmKM9pyWaRYApciSEE1dsczSJJfa6aBr7rHpGFaa+3a0TDmiZbhwr92OPQBraZkpJ/XSomWMwlUOkGaJiqQgPEoknI1DY813wyO8ml6+J9osWISOnWXL/47GakyR5No8Nuea811zh6q7QNsCAxfuprO7N/63aRnbL6FDae4TtMzEfKT1UpWimIiYks/aNyyTGeCBBGIcNTpyG2iW/1IPNeXtzKJQUYD7jLNCuDcux5ONCYdM0LJ6L4BpNpdtD+oobuXSYntRfAmmdljpwoe3SWOH5g6MzFY73Euaies4d5uW4dfkp0DLqPjgPaZlaA/0DVuUjvBEakX9VEZE01RijZuWMcZdo2XKdk10hLCArFonWRKZNI8GWyt1+Qt0BF2JFdRhIDEX7oJDZj+oZ6KNYy43yroxwN/poM+7uAC1rT55P0ebQz+Z/Yq2BBWJO8144236QdVcacea+6i/UMJ9cOUl6P0a9VdFRtlrSa4f17N2NauhAyXcdxstM0Q5p2WUtZ/F3NJpy32nZICzTLgPQbKRlqkRg2jXkLZEyReWLZhpNC6di6ZkNVG0e4qJnESBUf1P0QYqNItqSTMGNPM/CQPWR9FOu1SLoFmO2hfXjGgZgNMSkar+tw5iAYWp7K/hxA3T00/L8OfI00hV9kwKpQXyGjmARt1wrKVltLGT5QJ0YWzRMpMONDGmnZkxWggHsANiA9IjV/I0msw1CLsKNVHCPeGO1W6la+7qmYK2RBIFiNGBDC0QpiB9jRAOrliroaNHrhD+TpMosN67m5bRk7JG9xebpJWDIOruyygdjcqUxfAcRd8il+Yu+hUm4w1IvutSlZCw1omYI8S63njOMJWywbXpOCH59Jxp7lEKkBDEXrNeuJ8auhWjZbrsyHpahgQ4gQMItN077FgoF2BOzmXdI0g1zl0kInVLYH6Buqf2d0fmqVH9zzDP+bVEF1w6khxBu8QsDjCfRSy+Pj8EgCBoS7UI2lK1by9Eg5ZRglNlVG6gZsTYzS+QgtYIvyzWjO/kPTfQMrzdPAmRiVwFfQO0na7b0jKzc6QgUPXip2mZjcLdeu5sTbSMTcuIz1M0TtiVqAOVByDi3fuV5ejk7520SxyZp2q8+Pc56vFGJ+fd3IhcEe/3yDxlcxqEzTcnLdNNxqQb0U1CW+clqo/MuUVc98pK62o+RnwDdJRrFklMo2iZMGXv1e4jf/6gVXMdjbZOmlJZUfr6kfy7Nu+7CgQOemsKfByJmLO8HhFpKzVenpY5dYiwvaE4bJpvOlpGW9RkhlCruBf1FZogU4WrOKq2B9K5/Ns8CUEwIOwqJuTEPaGE++E5S8EWgkk61tJI9itI55Oae9BVyJOImXOiOl9SIOwsjUS0PwqF1DRkrfrfNvXH2fPw+xVHZAnlIuW0TDRj1SBPiZaZ0Fo02qtIQmSo5feir0FqOV23pWWSnHP6pbtcgGbpTGVKGn20nrvg0TKuGu3Ska4JrnUlIGI+BwVmxTkAYES0oC3le89Q4/A8QS7GS/t+KoOUpPqGOUfA18DhecLedZyz+T5By+hlNOz7B3zeyXlvrYey6dTcFGum3exQ7WxaRrxTW6kp2PGRxjpptXXSLlGkESJ0CIZ2vH4aTXkBkKFxbjpOcAthlmrRdkmBoNPOlF1nve4hzgrhLsL2aH4E0xmqCyDJUQcZE9AcUV+iDTOVIclRNh1C60SjGXhxJTk5WFtCCzkkNBUroUl3qAZTmntcIOqYIMqTkNW04ZOZCX1NC7Anp6iYp2sHOve37WlMjS7c2XmtaRQozcMRq7wR60xSbXyzJEIhhFWsnM5BwjMbudPVjkZKXZmlQivnVIAoF2A8v6ZxrqVltHHUkSXhKPxPQLxfXfvL19A48VChC5VwTzktQ+X77ZlzXBPih+YpCsI1d/59QVaT2bphWihaKs4RdWxcDmYxVyQmBCcA0B7LqRrnTSlLFasIGcd6sGrj27kAOgJnnLv5TiXaEkgPAmGCsLO0ZW2dZHE42gxHtIwYR6x251BNcpUHA7Dx7UuzL1N+pz3EWSHchYYTHLhgDefONEj7IIRkWKELZiPNqqx7hJnGCSehEj7zI+qeUPHThqYCNYEzzVkYzgq3BpfkiPoKRRoiTyNWjTKZA0mBuLdoGa6pyGfteGapi5ZpVQTBRs1d02CivlQROq3qy644d0rHm44Om5YhipYRfY1mc8PpqlMbxjGAOoRWnign9Uhz5g7optNyEVyYOEVoqgSx+M7edNZltCaWcM8LS7hLukwJn8PzRFk6/Hs3LSPm3dyIXIn6FZvTSYS4F1aipbnroZCueiu8WqiI7rEPrFHrQSX3iP6Ia13WgDsUUnunoygxNjejvtKiZUpjneZJiFzSWJZy1JrjmxGHBTQFzggY7zfJEdkKmadlTg1iEYQHLhzXXBHgL6ELM1nXHeALK8oNzYpSirLtEc/MaBkpfAqT81a0jK25a7win9RJVriPXEsKxH2FLImQxyFbcDE7DzUeKpOWSQ+YJVRlhUMXLVNuVX+cPc8SCGIgOxfxsFK0Ard6xCkzW0OUM5jU3E3aq9BoGWFFRZnpdK3aXkZRyNIONixaBtAKRwHK0jEqQu6elgHcsetl04/M+nURS+mwUglzAOIkRUPVnFE+DzbvMlLj8DxV41UIzt2hcXLBFc8OqMiVZI6Yn0ubJ2KuFWPLTMtQdY41/300OyCfG9BpGS0KTVM2AKUQOWvLTCUxTVkXfG7KdSJKVIt12ixQpBFyYo4X7M1TjmPtpqBcaBZAUrDaNbUKAoiHSo2Xp2UeBJolekoQFufLn8fXMAHVhZmq/Q61sPSdt+lZedgsTRnXzGmZkVknTcwQdDFXAAAgAElEQVQJWsY4sHcBRBmyNHUfuRYXSIYVck7LJMMK4rDrZOCLVhT2SsRCFIufP+8ELbP1IdlioSQF4mGFIuaap+DNd0vLyEiCKeFu9jEXm2ecS/9HnB3QrmGCYNUpIeKOvVbanB5GKekwzdJZW8ud98V4Fg51fOF4TJfa4dgC6wqNzbDCYGl2FVFF62zaIOe0TGbRMjmpHf4H5iyNZyLsk1EkybBCEYfIkpCth6RwCE7+mQ6o6may+macCc3dVGrctAz7G5fTWcBdfkB/p1ZYJKcMk74yD5HPzmXHTfLyIdmWtIxzk5wC33RYmK6iZZLB0tw9LXNqEOGMZMKEBiAFVBflmGma+wwrDFFmaFYGH8jjrGdxoDhOzQsPjB2qOi0jeeuWTQKx6MeHZOdIqaJlUlqxyRzn7OzXOGSJF7SXGv1ock7RMq44bxeEUzbOEYDinLhX42m3uQ1cm46OUbTM2KGazEztHlCCYTKxRlSW1GiZTKdlZHigamdtEhNvX8e6MXVtOutKQGR0pRLmOFaYjc8F5vNO0DJS2eDfZ1O0TJwjT1l2pIhcCTDgYDKgSCNWLjvJHbSM8l/VbTsp3KNZgYBo8360Hsa0TNV0LOvaceygM4lJf6d2QlMyxxAXyLDidWVUSK3Igs7jEAXs9StomdL4Pj8NtEw6rDwtczoQdCVWZDZpQgOQAorGOVIo4Z7TFYZ4bmhWhsbN46wJITgv4hltmhdev/6Iw6Eqz7Tkm8tk5EpSYEZXkpaZ0ZXqL+UUia4J6yVUN9Ey2wp3fQEBOD/hmiY3PVmbuxDu9tF/NtbQMmXTYxYHLFoGMCwQFZUxEeXioGUKXbhqB5vII/Z2ScusO5uW1Xgx71dMcO5912FGWlDLbF8FmRLuUhM9D5QEyEiNIy6H6hQtY8w7RZGcHzfI+FyjLoe5tqEFdJikZUgyN0pc6KHBAI9Cs2iZsulVko+FySQmm5aRlmzOFDRS83XC14WkmhaIwgAHIzsgYsIyIivnpuOERsuUGi0zoys2Xrxwm6dlThFBW7IkkHXCnb8EGmXI+UEIXdsgIZ0yq6TmrqVGJ6qe97lCuM/OYdy0iHO3aRmReq0dscfivYvpyJW4QIIW84hFhWRcm+rjHAVWZjKRTcvIybyBlnFQCOYYKVoGAM4Ti8GgZRZGTZ2N9xP9dUFuQKxee0ZWoCBANFPhiYmp3QP6EW67pWV69Xve/qnSMuuKgZVNpxx7HCKj1RBYAEpeOoNYZntDdM1d1J4v0IVsPhyapyOaIZuiZTSLUadIzo066Wjso1xaqQBUhE7CaLEQjhOvtHHU4/6XFi2zdNEyU/4STJUfcDhUhU8nZnRrLtaJlgynbwZSOcsPmf23hPt5YevcdJzQaBkRGkvjHDPZF4dVvU84K4R72FcsCWTiIF4AUkDRZI6UtOi7TpZUJYlpVhkhjBrHd27MJ0cyN4SruP6QTcvoBam4A2/ysGQuAM+JW8wTioR0oHHBwjRJbRbwsimS1qEhi3MrdVpmIl3eHKO5HMdzwkbdX7TJI1e2gn30n41oBpBAOn1z1GjDHCBEhSc6SkDotcJtDdmI0LGiZWQeg2bpuGLSDUzQMutyB5hD1RSE4r3bJQtE5UeSmppdozv+NQuoCzNkqHEwi3Ag4O+B0wnnBLUjLJS9U6OmvJhrUYOcOxrbMGPvfmhZzRUh8PjRfxEcG6kU7nOeg2A6VM8vdFpGKF6KlpnaUCNXElNrhUKK98zbb8McuYjzl+OVm+s35Os3nZvlENoSCCIgO4+PS+vslxN808mTCJSCVzIVfYmw0XrdQ5wVwj3uS1Z7fQtaRmhI5fKkPJCaJIVRTtbgYbWd/6BYTCJyRPP8z+IAc6v6H8vq08oWcA1Hb0OAcoF6MGxwDp+EfZShJRly1PxEJKXBuWkZawLxDSiNAgTEHbZnjpFJy8hJLrSmeM34uqClvjtBiFxkecw0yJbX0JdZo1qbNi3j0pBVhM44Wqa0aRmt3sqk5h7G45R3qDLDU6GQdrz5FDUmzscVseICXZixKBbA2NSbYMbohzjCOWGDAQTIWCDBwdCx6fJ3apwGJd5vyMJLM9Rog8ywkmSbKRPuIaajZRAzy6Cy1s88jdT3cpNUtMzUmLs1d42WAWVWhWY5CCXIOBxbbgbs5wPCErUjg2QMvVqDW4NvOsof1KEJMmSkQRHrY+SF+ykh7ium8U0Jdxn6Ngfh3NdqeVKeHRnNCoMTNWJwtclxMFScsG4eLmtWd0MIUZ2WMZ0qxWTkSsvjnA8GDQ4GrJ06yNGEGQpSI4+J5SjS+G8XLSOua/hBF0m0+ag93fQFcCCorQid3Qr3DZo7YHCi86BRpSBaLiDX0DLOao6aNolkDvQ10HdmkomDllmbbu6o6S42FVcEzHKClgHG713MwcDS3PswY051QNvU52iCTEZzHAwbptQEAWqS4UDo0Dg5LWNsLkKRCBoUSYAcNbN89fc70tzX0TKFUV6hFM7SOECRcjosTFjkSrNZuKtoGR5RJnnrQnHXeh+TAnWQKfqytdaJVM7c69dWXuQ63wYOpU0c8jMPW+3dPQRpGULIpYSQdxJCPkoI+Qgh5Ecd1zybEHKCEPIB/u/le9NdN5JhxZJApmiZVplpIY9dX5U7sqRqkM6lZjcMdJKWkWaw3PmFicmEjBCiOr2jqkku19IyQqgdCBrMeTt1MGOOYoiJIjROS/Nw0TLiOq0A2MZDsgW3ri1+VjFPROisob1c2ETLiN/J8a2xkpp7x8YqGUfLiDyBsh3TH0aEjuzvkjv8OpZf4KBl1qaba8XLBNblDrgOzZh67+L8UhFOKNBFBdIRLZOjDmYoSI0kCjAPallwrA5mSnjpELRMMqZlDgQ1irBDQCi7j9Au21LNLa65B5uEu0bLlE0vE+BklBAh0Ov3ryv5EErhLgbJmveibU0rbshMlV8wAg/UOjkQcEsnzkxaRviawggNYrXON0HbdPTxFXWCDpL6jNIy20TqdwB+nFJ6CyHkAID3E0LeTin9qHXdeyilLzz9XdyMlFbsxB65q9unrKgFH6RsMTTljqwmGc0OIKdsKFZdb/Kw+qEXpEGDCEkYQQ8bW2oV8zJNiFZNjwsPahUc9R3e0qIrpJgDmAc1woCFrdVIsSJsosxJYwpLY3JO0TKWQ3Gj5s6KfA1xgQBAETQGr6koki0PydbGfRLac8xJg1qr0HluHhtp63qEishFcMd1gz278A00rBTswDnRmWbpLBumHa8NfdOc6vKrkGWg2po4pdSplU4dki0OdRZlfuV9okwd+q7RHyuSYR7cDwCYBw1WNMM5AFZIUTiF+8KgZSp+wljI/37O/4ZFm2mCs+NtG5z7NC2TxyG+cKLiz6hoqcJI7lHjWDa9THKyEdqauy2sRduaBVaRFAnpkYeDFXiglId50KBGioyQsXLE77siGeZkS81d23R0B/uMz+G5vn4eirQMpfTzlNJb+OcdAB8D8Mi97thuMKMrdmCAFUsrIYXiXDvlZkeeHZnkhWG2ygiKODQE5JysUIm623FuhnXxvy80IbrUtZNGxMO6zXOhoRekxgEe4lYiw4rXmi/IyuEoWqqDBoJ4fNKLZl0Ycd5T4E7fOtDb1Lz9llNsI7bRWrQFX5AaFR+HStAyUSqdrrqANEo7TLUpN3vLGatZclWj5SJMQePuBaZqtE9tOlOhk+IIRZmsxTHEBYuYAiAS4BCEqKBCIAvU8iyCisxQEBfnrqI5ABalUsk5VcvY78qONhOb2YwVMQvJsIYCG9MywqLKrOQePat7Ey0jOXfnOzVpmQqZfKZx4MGS/24l59eYluHFz5Cye2wDbT1mmlUpxjcn9UObltFBCLkMwFMA3Oj49dMJIbcSQt5KCLlm4u9fTAi5mRBy87333rvrzk5hRmt2YMAULaO9BFFOta0Wsl52kh0wDjE2HKqaEM1Jo4S7RcuIiaoLUfk9pZKWmYpcETXlc9QyxK1EitKYKJZ5KkqocqE8gkbLFJtomb5lmm5SYDnwjQZ6m6dIy2w6XkzTrHKyQkl5+JygZYQ5b0XLiPHbDS3D/rbTHL2FmYsw2ccxLQMwasZ2qKpyBnaGqpuWERVNxfmpqs0cCenR1LVyJgIoaSqTl3KyUgfN0FQl6ejgtMwsCtlpUE0v51qGFXK+IZQ0tWgZ06EawUGBNUsW8RSEbCz0QAK+nszkHvWujWADC6Gdoep6pxYto29YU7RMjlrOLyctAybc862FuxYtxJ9lqY1vgRXOJC2ztXAnhMwB/AWAH6OUnrR+fQuAR1FKnwTgVQDe6LoHpfR1lNJrKaXXHjly5FT7bGDoe+SkZtEmIvxvkpYppIbU1wtZcCzJDmrnXHaomh5hQJg2F+cy/C/DCkvKwrtMWkaZrDq3LbWTbsVOeknykdNVYMHvm2GlCfcES6qE/oiWAdRCdE0eTTvJNtEymhAXC2BmtHmKtMymzDxNm8tQYyk0Uc0aEsfxxWGAJAxQNr12ytUaWsaojKkJV2HpRImZizAFBy0DiJIC5pguNwp3c4MVh1OLSpACItu6Wu7ILEgAWGIm50eGWs6PElrcu7z5IKNlgoDIyJWlpjCImvAlUrfgTLU499gx1nyMcy3aTFd2zJorKjiBHf6xIVqmF5r7ZlpmKddPbWw6SAp13CRqqSxN0TJLOlN18jdB23QMqxL6+nkI0zIAQAiJwQT7/0cp/Uv795TSk5TSBf98PYCYEHL4tPZ0AuJwbCJCyZKxCa0LRaEhddVCLqxZcUC+nGXdy2gHIrRGgAkIrLCgM5aIotEyesyuME+HgfJKenqs6xyEEOeB1SVfpBldSXN8McywGNiknYFTJCRgVEWiCVqRQWpDG4siidaHQmpO2WVPUNOI9ePB0jKbMvOSuVzwGV1hMcxAKTX8GIZ2n7ICb2KjmqqCaNMyRly6ZukYuQiTfSycz8wS30xhLX62aRkjzlyDPLOzOGh8L6JnVuUJ4/0uh0TOj4xWcn4shhQzmKdFydOj+N+KzWjZBmhpiNmgzbVen1MOWgYOWkYriJUnIVYto6SWTSef16i5wiNXKKXuKpMcMkOVbk/LiE0uHSpTqdCeKcMKiyFV3ztomSVNkNHdau5m5rloI0cFI3x5n7FNtAwB8HoAH6OUvnLimov4dSCEPI3f977T2dEpVFoiEgA5gQxotIzQkIZmKQ+xzYoDUpBUjXVepKbNpAMzg1ddPzIxxcsVma6VXsLAqrGSOSiSHb5IU7pitT4ALIYEC6FFDyslLIVDSDzbVFldzfRkGXRraBltAQnTPaWWWTmR0DMJ7ZzSSWgbUEpXWAwJ6m7AQGG+A/EcnOeerAmjWzcaLSMPyRa0jCbcp+gBidgxp+Au4zsVN69zsjrEeaiZpbkHXFmpyx2DltmhM6SogaHHjNbY4fNjQVNWskKHRQnIudkNqJBiBjXXdqgdLcP/lgv3NBjksXnq/ur9ykimlq+fWGnuep1zNCVW7QBKHVYXh0hi6mxaRn+nzdJwaIr1Q9rS2HR0TT+lKyxpyo6bdNAylFLsDKkck43QxjeP1eat1rKIluEROvuMbaJlngngPwL4ECHkA/y7nwVwFAAopa8F8CIALyGEdAAqAN9OXUfU7AFknLAQPHpyj4BGy8x4OjWtF/KQ4Fk2R54oc3HZaCVbNdM+pRVKmvK090LGUDOOUWgqrEaNkdaua79wR67s9IyXTocK0cAWxsk+QdmzxRt2pUoyEs8JsO9EnK4NYQbzgy6mjoVjz6ciSKqmR4mUaUF6GJp14MJGbEvLNEtgGJDSFXaGZMxba++Uxat3kgKYjJaJc3mkG5ol8gNalJJ29J+RizCFCVomSyKcqMzYcvFe7U1HxsVb74A0S1Q0QRaa14eGcFfjuNNzWrAtkdAKiz5hQqlPWCVRHVb+A5t3Hd+82fsN+RrYGWJNcC6Alt+L0zKFy22i9UvG8dedUWc/T0Kt5grTlsXamDqndMS56+9UL2PQLFlmaZSocRHfJ2PNPR0qVDiIsumQCFpGy2hetQMfl/ud/RrBQctUTQfC+5LoVsQ6n84eYaNwp5S+F8DanlFKXw3g1aerU7tBXfJwRhEnvIGWyeQpNyVIs2QOqjA0ONlKL9mqFTyK+xVKnMOED59ktFkYAkJqR1JAmbSM+G6k8bUUJU2RDCtNuMcoudBfN2nRLFWlOx1Jzrj+rh4dLj2CTsusOlQ0xVxMTnEvfvjvaadlOmW+nugTtfh1WmZ1gn3Hn0M8y1paplcZtoV+SLZFy8w3Hak2QcsUiQr/E3Adjg0AURggiYKR9UTaJSoyg63XCd9QWy3Y/M0uAcA2fPGcSV9hQVNGBdDUKGXN/tihubc9E8B0hsO92rxPdgnzV4Eny3UV+5k7w+cu4a6NY2GsH1UWQq+5QnjkyrrDsQEtWqZfQ8u0S8MCOzkk2vduWiYZKixxAQuzTQoAPNKsWwHJnCkNdIbYHscpaLRMEgWIQ4Jl06PjfYmEQnYGKBngLMhQbbjmHooMP51LkxcpARVGESqagLQlSFfK0Cg9CcGoDaLRH/HANXctnboudzBQldQiTHXDPHdoULZjTWhT0VAh7Fk7VUtxQtPUDMfpNrSMdUi2q3DVeIxYpcQl+CTXNyZ++O/2GaqL7WgZACiPAWDCSy5+nZYR3DSnZUbX6G2KCB3NhNc1S93SWXs4tkBcsGSVzgw1dDmp19Upzx3Wk6xoaiHSorp0Wua43OwXiIcVSsxwbMEchXFfmUXdrAxhoVSUPFxPf7/H+wQIAuXgFm0GXEi79j9tHI1IJp7EJNqkFFi1g7TSlObu3lSDUZy7xltHCetTIyxZ1v7xVm16RvSYRstEfYWK8rNOheW75FF7SS7XYNxvK9zNzZM5rHuc6GLZpv7u9hsPe+Herqw4YS38T0ILfQNYTC9plwhFNUmYSSZLnYfVaptEXYklZkaW34pbDvpkrtoei7pT99XiqsV3Y662Q4UUYbdkpjpmWDYdTnSaualNZlODmdAO5MReGpyoE7pzivcl6irY/gI9bngjpjYdVx8XbJHt9AlOrpjGbdAyWqZtadBejsQacU+hifLaNYCIllGaXdmuORxbQOPudRjOQo7JTQdwxsWHXYXGIdxTLty71cJ4v3I+LNlmWNKUCXc6AwEFq63DYSWRZYKWabki0SvL7LgQSILKE21y4Z5tScssG35qk6a5A1pNm26FctVMjpFAFBD0YqNqOW8dWTHq2rgcH1m41jpploj6arR+xbxTviY+LttgpLSxiKFlS7FCovpyBiJlgLNAuIs44WQTLROmQMizUMkMQVci7ErUPAM0t2gZWRtEOhGXCPsKFVKDlhGcvx4KCQD3L9kELow67KyPrsiVsumxwgyEax4rwtrZaSlaRGNaxuYep6JlALCqi9P1x9nzqcSPqulR0hRhz8PNRISOaPd00zKA1KCWmOHYgo1d7oyWicaW0ahNPhZCE22W0rKqLFpm8jQno4/uKCFR0kDHurNB2TGB5vWRqGhqIc2ZI7OvFzIUsusHnBRCjI9XiRTHFo0K8dMdvxYtU2i0TEln0o/TIsKi5cyrWD9CkVinuTtoGTHvVd6Htqnya0Vm+Kjom4YwIGYSU1Io3lps9ppW/IDUlm1aRvkRwq5iuSNNr74XmntcSFomoN3ISnNCbDrcWZrzOjpl0zNrTChknpY5NfQiEUlEG0zRMpppxGplV4j6Shb50WOojdog4u+q4wiGdkTLNDwUU6dlAODYgscix5pDVXds2UKh7lldFR6/W5OZ7MuKZA5aRhM4W9AySnOdiJjRNHcRLRO0lRLQRF/8e0DLLL8IgCWRiLHLHbRMHiufRuDKLLXDQvnfinIBS4uWmawJr2OiGmamhf8JLNdp7g4aJ+5LWTROR5qzd0frhZy/ZdvLkD8xXiVltIxI4jH6aNEymUbLlEgRdOz91mSmlA0RRSIEJ+HzOnLQedp8zKx5L8bUqGkjUvx5NdZ19XyigKCXnLvrnZZy0wOA43XE6sZM0TLlfSCgDlrmi/KeYlxkm5tgbTq6v60mM3ha5kFCJCLNch4n7ApbszTIOsgQ9SWvJqkWlorE6E1KAFBmMPhCEMKd00J60gYAHNvRNBhLg3IduVa2PSu7yjXxOshkVEgTzMYmnpi8q+Mys3QEBy0zqblbtMyKU1d6ZAn7/fw00zKmeVzS1Bw7cU1XAcMgIz5EaYdRZqndJg+NNcoFcM1O5CJsDIVcQ8sAJtU1uelAcbLGrUXRO/tano9BVsdZEh33hUghLsYLbLyk0HcJd93XU/M5RWYgfE41QaaUjREtw+d1aAl3UfZC4/MBfd5P0DLgVBPW0zKG5u56pyIWX/hOut5cJzYts1CW4XpaZqba3ARrbeRxJOcm68vC0zIPBiIJRKZvixevO5b0EEIALa+VnQymcBdlf0s7gQYwzGB9coiqfvZkvm/JNJjCPh4PcEauVE3HzHOuebRhJrWsJszHJp4ooco3nclQSGB3tEyUoWp6VqVSZCrq996WlpHlDDbRMvb4zuTYyQM0tPh6Rm30aw7HtqigWFlyslwAfyZx0PZWSUzi3hpcdYLWlTNgB1qYlhMT7uMNcJbNMVCCZHWffI6SO7oBjMZrW1qmbMWcyuScasJMbToTtMwssp5HP88Xagzlu0tMS1ZXiFpOpU4ebQgm3I0kJvudWlpx1XDlyPZBWfRLtZGWEZr7FnPcWhuiBANbP9o4elrm1CASkXKR4afXXBGwaJkuzJAMKySUHy/GkSUhFqsOq1bLxhOFq6QZLMw69neCFrI5RknLiDh3EjKBDDgjV5Z1zzQ4ziW2QSajQrogG5t4InJFmJVOWkYIpcVk+rsxRnEOBIyaYn1xmJXb0jJWbP8kLFqm1GmZODSv4fRS21OcqBwHNgNjKkindJIIVb1SNXTWRLYYmKBl5JhqVMu6cgauXIMZrTBEY809CEOskCCpxeadM2eoED7afDy2qFGt09w1WoZS4IGyYUoNf78dn2vyWR3RMpmtuY/u7Zj3UBugftRexythrtfcA41zn3inelkGsX6qB4xNR/6vr9/6NNMyHHqkXBd6WubBo11iRWOEkRXdomsw1s7fhTnSocLMEu55Eo0cQrJw1UJpSrrmLmghyTGmlnkahypjjmtzRTo258u2ZxocNzf7KOdp9h0rZ1zvMGpCN/GSQjMrHRqyFga2FS0jY795m33DaB+jzS1pmaka8zZss5nO1NhJv4eKDBLa/H2Lxh3lMkHLAOwdDSsz5JN9v0WcO29fh6vSY6knwFlwHZI9oysME2Z7STJkzf2qv+0aWmaKc9cKt4l5d2ynYXOtWwH1SXTROlqGC3ebc3eEWYp7s2dVJbDZuKhDsu0144LBuW+gZQS91oW5QbMAUPWm9PXbnkZaxhDuEae9enRRro3j/h+ODZwFwj1oVaw6AE1b1Sa5RcsMUYaU13ChOmeWhJpDSFugcS53+DYwhftQL43rRWLGsQU7UCEKg5HlkDmEQtV0TIPjtEwfcc295RNlaU1aq19O7UCnZdYcC8ceTC2gsunVpre899RoGSv8dBKWZiUcqmFAkISBeY1WuvfYot4FLaMJd42HFhTJVhmq+jNxKM7dpGWmknNyK7qGDgMy1MYc1FGTFEV7v3wOQ/hIS8dyqNq0jHZvfW4O2vvto1wegGI7KzvKFJKZrbnrZXUBWWhv5FAVioxGhQzcwR2H0+LHGS0jYFkXgl7ro0xbD5YDVptflUHLfFHeszoVWsaSH4z26tBLKnULv9Me4awQ7uKABwCGCS9hCdchzpHTarSw8iTEvXakhrgn3+GFRg1uStPadqiy/+/VhY+Vhu+KXFnWPVtwfLcfohwnqhZtT0EjXSOxzFPx/Za0jOtYODVGXHOvNeG+uPcUaZkt61gnWjtgmui9i1oVbtOvaZbG+DrNeqcJLxx4EVCrhJipUgEjbKBllhYtM7VZ2PkNdV0hIsPkGDUkw7wTmnuOsu4wIMAQpoYD+l4e5y6fX97A5HvFBn/vosYgap0s7sUQ5egGiqYflI+Cj2M1cOEe2Jr7uCCWvn4kLROPaRlaLzaOeRQSM4nJFtarE6z8R6ze4xBPrIdYWbhDlLPrY1tzz7Fs1BF529Ey5viK97tseja+y/sgz/M9A3jYC/ewL+XRbAA0WkYX7ubOT+MCBVkhINTQ8vIkws7Koc0lBVCf4Pfnhyrr2XxQk1mY5DsrzSlrOV4KxxFtVduDJjlESjRNCtkXGuda+xZFIr53mX7C6WodUeeELtxb5VNAfWLcZlcBwxYHfwCbaRlx7/oEaJiiR4idVWceU6fTMoljfO12J2iZIgllPSGdlll7xJ7+DFvSMvkaWqYbKCtcBWAli965zfY6yJAPZogqYM6HiqTYWXWoiEPjtIU7H9OdVcfOPwDYuMfKKSmT1OjAnM49E+6jMjCOOuX6+rFpmUqjZXQLbAohIRCsjPOd1ifl50qOi7ZOjc1AfU+TgllaUcLKPmvrmuWvOGjdKVjjWyQRmm5A0w2g8Ya1uQ942Av3qKvk+aMA3LSMHY6k7aRBYmru6rNOy2gbQ1IojTspQJolIo1C0DWSTNfcjR1+HGWx1J08gDGZqT1RHdc4tQN5bqUSipM13fWszabf3OamyS/pjw3CPYxYgpn1DCNajN/TfEeWgHBF6GjRMlkSsvBOfs+tDscGeJIKmXaoGtEy48OxBez3Xi3Z4hdFwmy0oam0qHmnno/wsSHaBigxYTGK+0lIX0tvzqO4QMnL88zCAQYcdcpzx9zXa66Ie5N2uVm4B8Q8Zs+mZWTf1XscbQDaNepvc7UGxPf8lKtl3al5v4116qBlBIjV5pnAw1+497Zwd/CjVjiSrikFqXtyjmgZ+XmuRRbkIF0pD8cGzAU0SctYzs1+oKi7wexjqvd3QohPCXodnEYJA+IsXCWhlUkt66AWcSQAACAASURBVB5kYjOcCgscYdtoGf2auJC5UobA1dp0bp7r2tRCY/MkRODQ3Ddy7oQ4fQ0uJ/W64+Ps6xteuiKYEO5G/Lumucv5ECaIE56El6RMEzV8TXY0h9ow9TlFpHDvzI0xKVB27IUkk7TMlHKkvScR38/naNCW2OTEDgPCCocNwzgc1/isrcd0agMwrXZ1MtTc+D1ztDpo3Sk4aBnV5gbFax/wsBfuyVBZi8DSYLoGGDpjgHVNKUhVHW3dnDYmX6JfnxuTI+wqgx4Q1f/YPfjLHi0yc5GLqJkgndqAtFrf1uJzfq/DoiXW0zJCc+8Q6Ac2u9rcFDGzLS2j3Z8khdwcjXKwWpv6WI/oFFebgurqViiSCEGnrim3pWXEPW1aJh07qSs9u9mC/d5rcUB75n53eiSXKdyVUBLjVKQRRqU3JmgZACCpPr/mql+WNVjxR5sFluY+QcsAGDlLWV5HJyNXgm4zLcM4dzo6cET0S0LQKdDKftvXa4I+nM2VA9wqUVA1PeIkZ6HPmyxTx6ajz80gmVg/+4iHvXBPh4p5yQVia+eVxX10Aa0+RzNtcrq0buNvCaIk18zjHKFjotrZqlOOLXEfUe86SN0WhaHZxRPm3pR2IOql83a3pWU2trlJs9mWltHvmeSSusi2oGXGh2M72tScoVkSqrK4sXqPGx2qvG+j8gOiRrtOrzXThcjs995UjDeO0gPO6w3hzvubxaHSuuNC9iGLQ4OCYg24LUbAVnDY52U9pmWWLdPYY1tzX0PL2OOZJaE6jjDJEW0h3GWcu5Vla7ep0zJhOje+H30OYqRpOqZlZKx8hyyNxuPoghUtJJ5TIJhNrJ99xMNfuFux6iPawKHN6ZqSfup8NknLFPL/fBYbtEzUV6PJLHZwg5YxdnhTgxP/R5q2bH6eMknVpgNHIoy8Rgr3NYdkc1qm6QZ0A0WUTmhKu6ZlttHcxfjOlSbqGn/LEec8sHmyv0zrl+eMaub8ugJW6j7z0TOHAcEsDqTmOAwUq3aYFFz2e5dF73K3cJdOTxICUQpZilrLvjSitGzrQj+RCKY1GjjmWtU6aBleUCzdJlqGWzJ2xm+uW4xJgaivNtMyhB+z55pHlsUq7h3OLF+LfX1SWH0xaZmq5UcubhMR5pArhgVvWNtbrIE9wMNeuM+gxewCY9rAYT7qAx9rgl43z42IB60SYx6bkyPuq1HURqYvOGAcb2xFrijhrlsU+uKbmCjiM88sdcJK4nEmMYlFlCgTN8o2UEFb0TJbHi+mPYfURHUBEYSs3KsWLcOu2ZaWYb/LkpAdNM6/L5te5SJsQpw7n1k/eMU4WtEB+733vMZKMkHLyNDBpAAIUcc/asJKnlU6Scu4NffEIdxdtMxSGKnEQcvo1UKhNsnRKVR6fH9cIB6qzbRMEDDOfd07BVT0GoB4NkFZxrpw10pAWLQM85dExpqZhGPT0Z/boNq8cD812IlIMvxvRMuoa3SBnmhCbNLkj01NSZ3mzjJdx5NZo2WGnp/0MqZlhHkoJr5uRcSGdaFrJA6KZJ3DRqNlJo/aaysA1Igg2djmNrRMnG93vJj2HHa+gP0csziQtxxp3BtomTwJkRN+fFyUrY1JH2FCm8tiVeFTRt9soGXEdUK4p1OaO58zlG+Q7OD2SI2XRsvkW9AyccgiVwBzrknh7qRl+McR584j0LT3a5ccUM+tKRVJjmQL4c6iZej6d8rvJ9aPFKjWpqMrZ8YasGiZsualI7ahZRx0kf5MxkbjaZndo6lXiElvxgnL8L9pWkZfTLLgGNSknMWBPMfR+NtkLgtXie8TuhrRA4aAcuzwIptPaBBi4uvm+dRnp+a+TjPQxqJIxoWrAGhjpKiKdFZAnq7oanMbWmZbjcWhiY5i2PlziOqOwDpaxtVfpvXnqBmNx2vorCte5WrfRpEqS07GzW8ZLSOyZTNRF8mC4MIFPSNLURsOVaG5W7RM17DToyxnnnR65tp64O07o2U45z7S3B0FsYrUvTEX+rGSSYF0WE3mAghEIUE3DFvRMnL9iA1LL1GtX58UZgkIR7RMISyjrWkZzfLX5lKaa+/Ua+67R7UQSQLWzqhlJbomhyHctZcwcoTq9wMkLdP2VJ6gntFKHo6t7qNx7i6HEP9daWnuqaZNOT9HM1mC1XimdU5LI0NzQnPXwtpkeGAauzcPKSw3ZPBZlMBauByEtoC0M03h0JCdnLvpjC2wkoW61hX5GiHOnc+cJZF0Fm4qRKYKjfENVpSrLtyauwhR7EOdNgjVMyW5SQHqtEzrGAutD3maSD+NqB1ftjYtU2DZ9GhpiAgOWmZ0b8vXxMHmHXvmIcqRYbXRzzHS3KdCC7m1mYSBojJtTVmjZTJ+Utow0DEtU/Pyz9tw7o5+6XMpyT0t86BQ8YMyRnHCWuaoS7jONOGeFWOH6igKQ6NlDN40yTFDjTw2h1HeJ4kmQwJ1rlZqy4W+6fB63kQtvvGk3ZKW2cS5N8rzr46vCzXz30HLbOIktYp9G2HRXrL9Nc/hvMYRwaFnHOZJiIzUssTuupj0EZLc+czMB8OTktrtaJmSW360XaKjAZJkfMweoKI/OrkZ9UyR0GgZ/XhHg07Q3qkONccjOW+S2RyEuGiZHFXToUcAAmveOOqUZ7FbORI1V8SzZJgoHaE/O+HH7K17p7KP3BcxtR505UysXz2mnZ9y1fSDmvdbJ+m5aRkpY4JYFm7bbzyshXstkkBmlkMqKdbSMtmcaesNDZGkamEJs2pk7hvRHGKBssMHAlAcTEyqQ5jlxQQtA5iRKzLeepapKny8j3kcanHNjud03Nu8Zs44/6E3HVs6NBPTSOxZq7nvDS2jzt60rSf1TieF+5a0jC4stxfu07SMvUlP0TLCXyDGmLQlSjIDmXCGy0OyeR5H1XQ8WkbRCcZZpTot46ANWN+0Oc7HhqRzRZ04InR6Eo7LTeyCltEVmS7MkZN6Y26BTGJa9061EtXF1HzVf+a0DCCycdU4lroznGd1r4VjfHWlUDICZ0hrBx7mwr0pRZywS7hP0zJJMkNHg9Gp87mucRv3G+/8stAXgHOC1rqPVldjDS1jO1RljG0QIc9y1Rct9G30nMBmWgaQtIRbc1e0jHHwtGuxiMiVPaJllCbq2GAb96lXRpt2hI71/DlWMqO5XBOTPoKIlhlMeiLTBNemQmTCXyCuC9olVnBr7YByyrWBcKiOaRkzFFKjEyYKtxk0TqzmjziFTNZc4RE6ZdNjQMASAXU4aJlsgpbJk5CF2PYDmmCGHKvtk5hctIxlUUp6bWo9WLSM+Btd0y8lpbYtLTMe3yAgyOIQWRwqNuGhLNwJIZcSQt5JCPkoIeQjhJAfdVxDCCG/TQi5nRDyQULIU/emuybEQbuRrbm7aBltkEkQoMQMK6TGn6lKdlO0jOKEq6ZHzQuWHQjMw3QN4dO6NXf9qD112DOfWEkhna6T9Ih+z020DCBpCb1wlYQWLmocPL2u3TNKy7iFiAw51Z1pWiE5Fi1Ty8p/pTDnt4EYY5ExycGO7jNpmXUbBuN8edJNV7GzNicgIpbEZlSJUD2dltEVkmTOauv03SQtY16vhJvpaCyUk7HpMJDQIdzHmrvcmNMxLQMwOqoJMuSokTmOIdQRBgET7i5aRhTtk33sLWVkap2o8TKO2kvm8h1uT8tMj2+ehOqQnzMUKQNsp7l3AH6cUvo4ANcB+CFCyOOsa74WwJX834sBvOa09nKqYyJO2A4lG9EyhGmbGlZkhpV16vxmWkZFJ7CzTdnfHwhr43IxgRgt4+bc9ciVqumRRjxCJynkRJYTRRSusrUAqXlsoGUASUuI9gxoC2gjLcOv2xtaZv7gaRm7TaGJ8qMGc9SoiRKWG4/Yk+2rioY68l3QMoBJ44R9xY5WnIBw/NfBDJRSFbqp0zJizuqbcbvcTMvI98sS4HQLhM1B5ZcYSDQW7u2Yc5eHxFvKkT7v6iBDRAbMY0vBsBASqAzVMGUF5nSMhHs4vR4clrch3LVYeTm+bTmy0sznn/ClpSEbBxG191DW3Cmln6eU3sI/7wD4GIBHWpd9A4A/oAz/DOBcQsjFp723Fjp+xN0oCUQPZRIL3oq3rskMjaU1CU50TMuoSZBpk6PiJvWcmMI924KW0SNXlnq8dZzLyZgnEfteHKk3xSXugpYR7RlYR8vYETrinqeVllHjOym4tXe6lpZxtcnN7CxmtIw42GJZ75KWAUbPLaguSql8n+usgUyjZeKuRBtMa+5CuFeYoe4GDJTfex0tA0DWYxfPrrcvNXdOy3DeOk+UBaLPwbLpQV2cu2OsDTrSGiOAjbcY+8JaMzak5r7unWq0jKGMrKFl8ilaxraegfXae7MwTrmSzxpHsoa9vgGdCWw5sxkIIZcBeAqAG61fPRLAZ7WfP8e/+/yD6JsTH7/lH3D83a8FAMyXnwHgSAJJCnbCyht/CPjsjc4BroOMHTytQXCiI83LcMiwIXvdu+/EU+kxvAzANZ94DbDzv+Tlzzm2wIHoATzmH98ELD/F/3asQX3h5Aove8OteN+n7ldCRovRzZNQOZ7WCfe1mjv/3TtegWfUBX49ug+fev0f4HNaVuaF9afwKAAvf+uncPM9FISwjc7ZprjnXe9n4zuF6oHRM2/so7b43Jr7DvDGH8J33XM/vjwpEb75evOaz/wzMHPEjCdz4I6/R/jmH8YF5DjeeRL4vTfcikW9myQm3se//Tlgdq78+oVfOIlHBSfwvt/6n7isavDrUYvib/4XZI6AhZet7kH56R43/eYMVzSfxOdmXzLZ5Kw4BwBw6z0tfucvPgiAa966paNvdAMf77f+1OTB6UUSqhLV2vvNkxAfvfskXvaGW/EjywBtQPCaN9yKO+5dYAhcwr103hsYF2ITffy/33obrr2/xGMBPPrGlwMfPWfy2b/97vvx7GYF3PFpOY/eedsXcf2HmEh5aRVi0VK87g234tP3lXjUoYIJ2jBZu05EX177D3fgY+E9eDGA1990L95FP8H6qpd3eMuPjix+ic+9z7k2crvg3cNBuBNC5gD+AsCPUUpPnkpjhJAXg9E2OHr06KncAuUDn8fR4zfJn/81+hJcduGl5kWPeibw8b8F7nwX+/nKrx7d595HfhVIPH5xL3ziI/DMKw6bX+aHgSufBxx9Oi45L8PjH3kQn75viZP0HLwoOIpLF7cDd94pL790GHAwbXHg7tsBEODS64D8fOOW111+Pt57+zHccDtbhM+56gL2iy95PtCyLMqvueYinF+wQ7XxuH8PXPwks19xAVz1QuCyZzpGiuPIVezfPR/BxcOAZ8UN6M74slvINXjHnSUGEuK5V13AShhf/pVuAX35c4EP/JEaXxcOXAwcffr073Vc/CR27YXX4CkHZrjuMefjUYcsbe3S64BzLgHufBeuaXtcnvTAnbc7+vaV4++u/GrgE38H3PkuVPF5uHG4GjfcfgyPODfDtZedt10fL3oCcOhK4O4PGF8/putxftyCHmc/xylBcOcdk7d5Gm2xHHrgONAgQXnJl01ee+DgeXjf7Om4oX0sbvnk/XjUoRxPvOQc4NB5bI4/4il4XHIQ/+ay83DVxQeA6onAoSuAu25hN3jklwLzi4x7PuOKwzi56tj7veK5QMae/8uvPIw7vrjADbcfw5XdU9Aixg23H0Meh0iC2KRlKK/WaNUzuuS8HM+4/BCeetQc06suOojLjxT4yF0nUA+PxAuDR+Die28B7p3OXr6yanDpMADdTK7f37vhk7jxzvtxeJ7g6u5a7HRz3HD7MRxIIzzj8kPsDx//IuAxzzJvNr+Qzdmj1+HooRxXX3wQn7x3ieP0XDyNXI03feF8HCMLXHXRATz6UAGETwXOfwxTFtbhyueNvvqqqy9UP1z99WzOniEQSunmiwiJAfw1gLdRSl/p+P3vAHgXpfSP+c//CuDZlNJJzf3aa6+lN9988yl33MPDY5/wqi8FLnoi8C3/g/3ct8AvHwae83PAs162J02+/E0fxltuvRv/8nIlQL/1d/4JAQH+5MVbKg1nKQgh76eUXrvpum2iZQiA1wP4mEuwc7wZwHfzqJnrAJxYJ9g9PDweRggsh2rPQ3/3MDknINoB2RxdP6w9VNvDxDa0zDMB/EcAHyKECJv0ZwEcBQBK6WsBXA/g6wDcDqAE8L2nv6seHh5nBEHEzlQV6Hno7x4K9yggrESAhranXrjvAhuFO6X0vZjyDqlrKIA13jUPD4+HLYJwQnNP9qzJMBxr7m0/yKqWHpvht0EPD4/1sJOYhr2nZSJROExD62mZXcGPlIeHx3qMOHdOywR7J9zlMXsaPC2zO/iR8vDwWI8gMuPc94OW4bkeOu/uaZndwQt3Dw+P9bCTmPYhWibiQrwzhLvX3HcDP1IeHh7rMUXL7KXmzk9C60eauxdZ28KPlIeHx3pMRsvsrUMVADtqj8PTMruDF+4eHh7rYWvu+xAt49LcO0/L7Ap+pDw8PNZjMolp/2gZSimafkDkhfvW8CPl4eGxHlO0zJ6GQprCXThWE0/LbA0v3D08PNbDTmLaV86dC/ee/e9pme3hR8rDw2M9zki0DBNNQnNvekYLeVpme/iR8vDwWI/JJKb909xbLtw9LbM9vHD38PBYj1ES095XhQwszl0Id0/LbA8/Uh4eHusxGQq5d7RMZDtUOefuaZnt4UfKw8NjPc5gtIxIYmqk5u5pmW3hhbuHh8d6jDj3/TmsAxjTMonX3LeGHykPD4/1mDxmb++TmHwo5KnDj5SHh8d6BCFA9zdaRgj3YRQK6WmZbeGFu4eHx3pMHtaxzRHMpwZbc287T8vsFn6kPDw81kNkqFJexGtoGSVD9k6LjqwkJiHk48iLrG3hR8rDw2M9hIYuiof17Z7y7cBYc5e0TOBpmW3hhbuHh8d6BCH7X1AzfbOnlAygR8swoS5oGe9Q3R5+pDw8PNZDCHIRDrmPmjtX2FVVSE/LbA0/Uh4eHushhbvQ3PdTuHPN3dMyu8ZG4U4I+T1CyBcJIR+e+P2zCSEnCCEf4P9efvq76eHhccbgomXC/aFlJOfuaZldY5s39P8CeDWAP1hzzXsopS88LT3y8PB4aMGmZYb91Nytwzo8LbM1No4UpfTdAO7fh754eHg8FCE0d3omOHez/ICnZbbH6doGn04IuZUQ8lZCyDWn6Z4eHh4PBYw4972PlhmFQgpaxmvuW+N0vKFbADyKUroghHwdgDcCuNJ1ISHkxQBeDABHjx49DU17eHjsOYiLc99bzX0qiclnqG6PBz1SlNKTlNIF/3w9gJgQcnji2tdRSq+llF575MiRB9u0h4fHfmAUCtntexKTiHP3tMz2eNDCnRByESEsD5kQ8jR+z/se7H09PDweIjiD0TJ9r0IhCVFC32MzNr4hQsgfA3g2gMOEkM8B+AUAMQBQSl8L4EUAXkII6QBUAL6dUlGEwsPD42GPkebeAOG5e9ukEO5ckjQ9RRwGIHtYz+Zsw0bhTin9jg2/fzVYqKSHh8fZCNuhOuw9LWOXH+j6wfPtu4QfLQ8Pj/Vw0jJ7V8sdcHDu/eBrue8SXrh7eHish4uW2cPzUwGdcxdVIanPTt0l/Gh5eHisx0hz3/9oGU/L7B5+tDw8PNZD1nPXHap7q7kTQhAQYKCeljlVeOHu4eGxHq4M1T0W7gBLZFKcu6dldgs/Wh4eHuthZ6juQ7QMwKgZvbaMF+67gx8tDw+P9XDGue+H5k7Q9bpw97TMbuCFu4eHx3roDlVK9yVaBgDCkGiHdXhaZrfwo+Xh4bEeuuYutPf9oGUIQU+95n6q8MLdw8NjPXSHat+wz/tAy3jO/cHBj5aHh8d6SFqm31fhbnLunpbZLfxoeXh4rIfOufct+7wftExoa+6eltkNvHD38PBYD52WGYRw3+849wGR19x3BT9aHh4e66FnqEpaZu8194BAc6hSX35gl/Cj5eHhsR7EQcvsQyhkFASycJinZXYPL9w9PDzWQw+F7PePlgkDYpQf8LTM7uBHy8PDYz0Mh+r+0TKRkcTkq0LuFn60PDw81sOIcz9TmrunZXYLL9w9PDzWw8hQ3UfhTogs+dv5OPddw4+Wh4fHejiTmPanKmTXU1BK0fhQyP+/vXuNsaOs4zj+/c05WxRMKJcGsRdbtWqIN3BDSjSGgCYFDTVRE9CESzB9AwGNiYGYYOQdiRElIZgGKpcYIFajlTQSBBJegSxKaqEgC166TbErl2qU0t3u3xcz051d2s6Z07Mze6a/T7LpzjmnPc88T/Pf2d95nnkqc2+Z2dE1NVsmW8SURzNLHMtU4uJuZkeXJKCkgcw9XcSU34LAsUw17i0zK5d0a1/E1Mm22TtwMJ0x41imGveWmZVLus1cuR8MprLi7limmtLiLmmzpL2SdhzheUm6TdK4pO2Szhl8M82sUerUPlumm93y17FMf3rprbuB9Ud5/iJgbfa1Ebjj2JtlZotK0ql9EVOnI6ZnZg5duTuWqaa0tyLiCeD1o7xkA3BvpJ4Elko6c1ANNLNF4B2xTA0rVLMr9zxz9yKmagbxo3A5sKtwPJE9ZmZtkXTn3lsmX9i0gPJt9vJYxrcfqKbW3pK0UdKYpLHJyck639rMjkXSaWQR08HCB6qOZaoZRG/tBlYWjldkj71DRGyKiNGIGF22bNkA3trManEoc68xlumk95ZxLNOfQRT3rcDl2ayZdcC+iNgzgH/XzBaLQ5l7duWe35JgAeUbZE9N51MhfeVeRWlwJul+4HzgdEkTwPeBEYCI+CmwDbgYGAf+B1y1UI01s4bkxX1mKr1q18JfRefb7OW3H3AsU01pcY+Iy0qeD+CagbXIzBafQytUp2qJZAASiRnHMn3zj0IzK6fCB6o1zJSB2cw9j2W8iKka95aZlSt+oFrTlXueueexjIt7Ne4tMytXXMRUU3HvJnNXqDqWqcbF3czKFWfLdOqJZTqJmAl427FMX9xbZlYu6cLMzOxsmRp0shk5eXFf0nW5qsK9ZWblkqT+zD2LYfYfOAikMY31zsXdzMrNiWUW/na/MFvM35pKi/uIr9wrcW+ZWbniB6o17J8K6WYdAPuz4u4VqtW4t8ysXPGukDXOloHZK3fHMtW4uJtZuaQzu4dqTbFMkhXz/VMzSOnsGeudi7uZlVOncG+ZejP3t6cOMtJJUA33s2kTF3czK9fAIqZOIZYZ8VV7ZS7uZlau4dkynilTnXvMzMod+kD1QI2zZfLM/aBXp/ahnnXEZjbckiQt7qj2WGb/1IxjmT64uJtZuTyWiZnaY5n9jmX64uJuZuXy4g61Ffd8EdNbjmX64h4zs3J55j4zXfsipv1TB72AqQ++cjezcvkippnpRhYx+Y6Q1bm4m1k5ddI57jXe8nfOVEjHMpW5x8ysXNJNCzvUPhXywPSMY5k+uLibWbniptg1z5YBb9TRD/eYmZWbU9zrnecO3mKvH+4xMyuXdGa/r20qZLG4O5apqqfiLmm9pBcljUu64TDPXylpUtKz2dc3B99UM2tMw8W96yv3ykpny0jqALcDXwAmgKclbY2I5+e99MGIuHYB2mhmTWsglukmswXduzBV10uPnQuMR8QrEXEAeADYsLDNMrNFpVjca54tA45l+tFLcV8O7CocT2SPzfcVSdslbZG0ciCtM7PFoYFYputY5pgMqsd+C6yOiE8AjwD3HO5FkjZKGpM0Njk5OaC3NrMF1/BsGccy1fXSY7uB4pX4iuyxQyLitYh4Ozu8E/j04f6hiNgUEaMRMbps2bJ+2mtmTZBnywybXor708BaSWskLQEuBbYWXyDpzMLhJcDOwTXRzBrX8CImxzLVlc6WiYhpSdcCDwMdYHNEPCfpZmAsIrYC10m6BJgGXgeuXMA2m1ndvIhp6PR047CI2AZsm/fYTYXvbwRuHGzTzGzRmPOBahNTIR3LVOUfh2ZWrljck3puJluo7Y5l+uAeM7NyDS9icixTnXvMzMo1PhXSsUxVLu5mVm5O5l5PLOPZMsfGPWZm5Rq4ck8Soay+O5apzj1mZuVU/2wZgE5W3b2IqToXdzMrN+fGYfVtvZzn7r5yr849ZmblGohlYDZ3d3Gvzj1mZuUaWMQExSt3xzJVubibWbk5sUznyK8bsHyWjO8KWZ17zMzK5QW9s4RDU1jqeNvsvTwVsjr3mJmVy6/ca4xkoJi5O5apysXdzModKu713O4359ky/XOPmVm5PJapaf/UXLfj4t4v95iZlWsolvEipv65uJtZuXyFqmOZoeEeM7NyztyHjnvMzMoVp0LWaDZzdyxTlYu7mZVr7Mo9LVEjXZeqqtxjZlauodky+QX7SOJSVZV7zMzKNbaIKbtydyxTmYu7mZVr8ANVae6We9YbF3czK6esVNRc3LsdMZIkqMb72bSFi7uZlZPSq/e6FzElciTTp56Ku6T1kl6UNC7phsM8f4KkB7Pnn5K0etANNbOGqVN/LCN5pkyfSntNUge4HbgIOAu4TNJZ8152NfBGRHwIuBW4ZdANNbOGJd36Z8sk8gKmPvXSa+cC4xHxSkQcAB4ANsx7zQbgnuz7LcCFckhm1i4NxDJp5u5S0o9eivtyYFfheCJ77LCviYhpYB9w2iAaaGaLRNJALJMkjmX6VN825oCkjcBGgFWrVtX51mZ2rC68Cd778Vrf8uvnruL8Dy+r9T3bopfivhtYWThekT12uNdMSOoCJwOvzf+HImITsAlgdHQ0+mmwmTVk9Kra3/K8DzoA6Fcvv+88DayVtEbSEuBSYOu812wFrsi+/yrwWES4eJuZNaT0yj0ipiVdCzwMdIDNEfGcpJuBsYjYCtwF3CdpHHid9AeAmZk1pKfMPSK2AdvmPXZT4fv9wNcG2zQzM+uXP4Y2M2shF3czsxZycTczayEXdzOzFnJxNzNrITU1HV3SJPD3Pv/66cC/Bticxex4uIhurQAAA5JJREFUOdfj5TzB59pGdZ7n+yOidNluY8X9WEgai4jRpttRh+PlXI+X8wSfaxstxvN0LGNm1kIu7mZmLTSsxX1T0w2o0fFyrsfLeYLPtY0W3XkOZeZuZmZHN6xX7mZmdhRDV9zLNuseVpJWSnpc0vOSnpN0ffb4qZIekfRS9ucpTbd1UCR1JP1J0kPZ8Zpsg/XxbMP1evd0WwCSlkraIukFSTslndfWMZX07ez/7g5J90t6V1vGVNJmSXsl7Sg8dthxVOq27Jy3SzqniTYPVXHvcbPuYTUNfCcizgLWAddk53YD8GhErAUezY7b4npgZ+H4FuDWbKP1N0g3Xh92PwF+FxEfBT5Jer6tG1NJy4HrgNGI+Bjp7cEvpT1jejewft5jRxrHi4C12ddG4I6a2jjHUBV3etuseyhFxJ6I+GP2/X9Ii8By5m4+fg/w5WZaOFiSVgBfBO7MjgVcQLrBOrTgXCWdDHyOdL8DIuJARLxJS8eU9Bbi7852YzsR2ENLxjQiniDdq6LoSOO4Abg3Uk8CSyWdWU9LZw1bce9ls+6hJ2k1cDbwFHBGROzJnnoVOKOhZg3aj4HvAjPZ8WnAm9kG69COsV0DTAI/y+KnOyWdRAvHNCJ2Az8E/kFa1PcBz9C+MS060jguijo1bMW99SS9B/gl8K2I+HfxuWzrwqGf3iTpS8DeiHim6bYssC5wDnBHRJwN/Jd5EUyLxvQU0ivWNcD7gJN4Z4zRWotxHIetuPeyWffQkjRCWth/HhG/yh7+Z/4rXfbn3qbaN0CfAS6R9DfSaO0C0mx6afYrPbRjbCeAiYh4KjveQlrs2zimnwf+GhGTETEF/Ip0nNs2pkVHGsdFUaeGrbj3sln3UMoy57uAnRHxo8JTxc3HrwB+U3fbBi0iboyIFRGxmnQMH4uIbwCPk26wDi0414h4Fdgl6SPZQxcCz9PCMSWNY9ZJOjH7v5yfa6vGdJ4jjeNW4PJs1sw6YF8hvqlPRAzVF3Ax8BfgZeB7TbdngOf1WdJf67YDz2ZfF5Nm0Y8CLwG/B05tuq0DPu/zgYey7z8A/AEYB34BnNB0+wZwfp8CxrJx/TVwSlvHFPgB8AKwA7gPOKEtYwrcT/pZwhTpb2RXH2kcAZHO6nsZ+DPpDKLa2+wVqmZmLTRssYyZmfXAxd3MrIVc3M3MWsjF3cyshVzczcxayMXdzKyFXNzNzFrIxd3MrIX+D4CJyUPLZnm4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mod_taken)\n",
    "#plt.plot(base_taken)\n",
    "plt.plot(taken)\n",
    "#plt.xlim((0,25))\n",
    "#plt.ylim((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
